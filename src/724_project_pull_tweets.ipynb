{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "representative-stamp",
   "metadata": {},
   "source": [
    "# AIT724 Project - pull tweets\n",
    "# Melissa Cirtain\n",
    "\n",
    "#### Deliverables:  10-20k tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "civil-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-jacksonville",
   "metadata": {},
   "source": [
    "# Instructions to run:\n",
    "1. enter your twitter token value in the cell below\n",
    "1. enter your topic value (what you want to search for) in the cell below\n",
    "  - Pull 5000 **\"maga\"** and 5000 **\"statehood\"**.  \n",
    "1. run this noteboook until you have 5000 tweets on your topic.  You may need to take a 15-minute break between runs to not cap out.  References below explain limitations.\n",
    "1. upload your data files to https://github.com/sareek/NLP_on_Social_Media_Data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "human-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_token = \"PUT YOUR TOKEN HERE\"\n",
    "my_topic = \"maga\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-rates",
   "metadata": {},
   "source": [
    "### Helper functions and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aquatic-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the token, which you specified above\n",
    "os.environ['TOKEN'] = my_token \n",
    "\n",
    "\n",
    "def auth():\n",
    "    '''return the Bearer Token (which should be set in the env)'''\n",
    "    return os.getenv('TOKEN')\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    '''return the authorization header with bearer token'''\n",
    "    headers = {\"Authorization\": f\"Bearer {bearer_token}\"}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def create_url(keyword, max_results=10):  \n",
    "    '''Generate the URL with query baked in and return search results\n",
    "    There is an API limit of 200(?) tweets, and time limits as well. \n",
    "    20 requests per 15 min.\n",
    "    '''\n",
    "    search_url = 'https://api.twitter.com/2/tweets/search/recent' # use search recent not search all (no access)\n",
    "    \n",
    "    # define query parameters:\n",
    "    query_params = {\n",
    "        'query': keyword,\n",
    "        'max_results': max_results,\n",
    "        'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "        'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,' \\\n",
    "                        'created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "        'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "        'place.fields':'full_name,id,country,country_code,geo,name,place_type',\n",
    "        'next_token': {}\n",
    "    }\n",
    "    \n",
    "    return (search_url, query_params)\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token=None):\n",
    "    '''given search arguments, connect to API and return response'''\n",
    "    params['next_token'] = next_token  # params obbject received fromo create_url()\n",
    "    response = requests.request('GET', url, headers=headers, params=params)\n",
    "    print(f'Endpiont Response Code: {response.status_code}')\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "        \n",
    "    return response.json()  # return response as JSON\n",
    "\n",
    "\n",
    "# Revise connect_to_endpoint so I can iterate over pages\n",
    "def connect_to_endpoint_2(url, headers, params):\n",
    "    '''given search arguments, connect to API and return response'''\n",
    "    #params['next_token'] = next_token  # params object received fromo create_url()\n",
    "    response = requests.request('GET', url, headers=headers, params=params)\n",
    "    print(f'Endpiont Response Code: {response.status_code}')\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "        \n",
    "    return response.json()  # return response as JSON\n",
    "\n",
    "\n",
    "\n",
    "def collect_tweets_to_df(keyword:str, tweets_count=100):  # TODO: max_results here should be variable, but call to create_url() maxes at 100.\n",
    "    '''Return a pandas df containing results of a query based on\n",
    "    provided keyword and a parameters list.  \n",
    "    '''\n",
    "    max_results_per_free_request = 100\n",
    "    headers = create_headers(auth())\n",
    "    search_url, query_params = create_url(keyword, max_results_per_free_request)\n",
    "    my_data = []\n",
    "    next_token = None  # to keep getting more tweets if available\n",
    "    \n",
    "    while len(my_data) < tweets_count:\n",
    "        # keep getting responses until we have needed number of tweets\n",
    "        my_response = connect_to_endpoint_2(search_url, headers, query_params)\n",
    "        \n",
    "        # collect each set of responses until we have them all or meet our requirement\n",
    "        my_data.extend(my_response['data'])  \n",
    "        \n",
    "        # get next page of tweets, if available\n",
    "        if 'next_token' in my_response['meta'].keys():\n",
    "            print(f'next_token found: {my_response[\"meta\"][\"next_token\"]}')\n",
    "            #return None, my_response\n",
    "            \n",
    "            # get next page of tweets\n",
    "            query_params['next_token'] = my_response['meta']['next_token']\n",
    "\n",
    "        \n",
    "    # convert to dataframe keeping the interesting fields\n",
    "    fields_to_keep = ['text','created_at', 'id', 'conversation_id', 'referenced_tweets','lang',\n",
    "                      'author_id','public_metrics.retweet_count','public_metrics.reply_count',\n",
    "                      'public_metrics.like_count','public_metrics.quote_count',\n",
    "                      'public_metrics.impression_count'\n",
    "                     ]\n",
    "    \n",
    "    #df = json_normalize(my_response['data'])\n",
    "    df = json_normalize(my_data)\n",
    "    \n",
    "    # Keeping all the data for now.  We can reduce later if needed.\n",
    "    #df = df[fields_to_keep]  # warning - will break if twitter changes their API/fieldnames\n",
    "    return df, my_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-induction",
   "metadata": {},
   "source": [
    "# Pull the tweets\n",
    "\n",
    "Just run the following cell and you'll pull some tweets.  You should take a break between runs.  I will add timestamps to the saved files so you don't accidentally overwrite your output.  Run until you have 5000 tweets for both topics, then upload the files to github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "framed-killer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpiont Response Code: 400\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "(400, '{\"errors\":[{\"parameters\":{\"query\":[\"maga lang:en start_time:2023-03-06T01:00:00Z end_time:2023-03-06T23:59:59Z\"]},\"message\":\"There were errors processing your request: missing EOF at \\':\\' (at position 41), no viable alternative at input \\':\\' (at position 38)\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a221cd408e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmy_keyword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{my_topic} lang:en start_time:2023-03-06T01:00:00Z end_time:2023-03-06T23:59:59Z'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmy_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_tweets_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_keyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n\\n\\n***** PULLED {my_df.shape[0]} tweets *****\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-51a5cd35780e>\u001b[0m in \u001b[0;36mcollect_tweets_to_df\u001b[0;34m(keyword, tweets_count)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtweets_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# keep getting responses until we have needed number of tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mmy_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect_to_endpoint_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# collect each set of responses until we have them all or meet our requirement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-51a5cd35780e>\u001b[0m in \u001b[0;36mconnect_to_endpoint_2\u001b[0;34m(url, headers, params)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Endpiont Response Code: {response.status_code}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# return response as JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: (400, '{\"errors\":[{\"parameters\":{\"query\":[\"maga lang:en start_time:2023-03-06T01:00:00Z end_time:2023-03-06T23:59:59Z\"]},\"message\":\"There were errors processing your request: missing EOF at \\':\\' (at position 41), no viable alternative at input \\':\\' (at position 38)\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}')"
     ]
    }
   ],
   "source": [
    "# try it out\n",
    "#keyword = \"memphis lang:en -is:retweet\"\n",
    "#my_df, my_response = collect_tweets_to_df(keyword)\n",
    "\n",
    "#my_keyword = f'{my_topic} lang:en'  # by default keyword search is case-insensitive; retweets appear truncated\n",
    "\n",
    "# Test time bounds:\n",
    "'''Windowing over time ranges using start_time and end_time in query parameters. Type should be ISO 8601 date, i.e. YYYY-MM-DDTHH:mm:ssZ. This sets the newest, most recent UTC timestap to which the Tweets will be provided.'''\n",
    "#YYYY-MM-DDTHH:mm:ssZ\n",
    "start = datetime(2023, 3, 6, 0, 0, 0)\n",
    "end = datetime(2023, 3, 6, 23, 59, 59)\n",
    "#my_keyword = f'{my_topic} lang:en start_time:{start} end_time:{end}'\n",
    "my_keyword = f'{my_topic} lang:en start_time:2023-03-06T01:00:00Z end_time:2023-03-06T23:59:59Z'\n",
    "\n",
    "my_df, my_response = collect_tweets_to_df(my_keyword)\n",
    "print(f'\\n\\n\\n***** PULLED {my_df.shape[0]} tweets *****\\n\\n')\n",
    "display(my_df.head())\n",
    "\n",
    "# write df to tsv\n",
    "timestamp = str(datetime.now()).replace(' ', '_').replace(':', '.')\n",
    "file_topic = my_topic.replace(' ', '_')\n",
    "output_path = f'{file_topic}_project_tweets.{timestamp}.tsv'\n",
    "\n",
    "my_df.to_csv(output_path, sep='\\t')\n",
    "print(f'Wrote data to {output_path}')\n",
    "\n",
    "# write also to json (just in case)\n",
    "output_path = f'{file_topic}_project_tweets.{timestamp}.json'\n",
    "\n",
    "my_df.to_json(output_path)\n",
    "print(f'Wrote json data to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "commercial-trainer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 3, 6, 0, 0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "clinical-crossing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data to maga_project_tweets.2023-03-08_21.15.55.808461.json\n"
     ]
    }
   ],
   "source": [
    "# DELETEME, just testing:\n",
    "\n",
    "# # write df to tsv\n",
    "# timestamp = str(datetime.now()).replace(' ', '_').replace(':', '.')\n",
    "# file_topic = my_topic.replace(' ', '_')\n",
    "# output_path = f'{file_topic}_project_tweets.{timestamp}.csv'\n",
    "\n",
    "# my_df.to_csv(output_path, sep='|')\n",
    "# print(f'Wrote data to {output_path}')\n",
    "\n",
    "# Write to json?\n",
    "timestamp = str(datetime.now()).replace(' ', '_').replace(':', '.')\n",
    "file_topic = my_topic.replace(' ', '_')\n",
    "output_path = f'{file_topic}_project_tweets.{timestamp}.json'\n",
    "\n",
    "my_df.to_json(output_path)\n",
    "print(f'Wrote data to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "transparent-scotland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "      <th>public_metrics.impression_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>geo.place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1633648438993883136</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @GabiNga1: @keith0sta @827js @1mir_r @45tf5...</td>\n",
       "      <td>1633648438993883136</td>\n",
       "      <td>1298715879673274370</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633505762881282...</td>\n",
       "      <td>['1633648438993883136']</td>\n",
       "      <td>2023-03-09T01:58:34.000Z</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1633648437798522881</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @OccupyDemocrats: BREAKING: MAGA Gov. Sarah...</td>\n",
       "      <td>1633648437798522881</td>\n",
       "      <td>615777223</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633546143337680...</td>\n",
       "      <td>['1633648437798522881']</td>\n",
       "      <td>2023-03-09T01:58:33.000Z</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1633648433977335808</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @OccupyDemocrats: BREAKING: MAGA Gov. Sarah...</td>\n",
       "      <td>1633648433977335808</td>\n",
       "      <td>1393026118303854594</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633546143337680...</td>\n",
       "      <td>['1633648433977335808']</td>\n",
       "      <td>2023-03-09T01:58:33.000Z</td>\n",
       "      <td>2300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1633648433507573763</td>\n",
       "      <td>en</td>\n",
       "      <td>@ybarrap We demand justice when cops shooting ...</td>\n",
       "      <td>1633564967164100615</td>\n",
       "      <td>739248656</td>\n",
       "      <td>[{'type': 'replied_to', 'id': '163356496716410...</td>\n",
       "      <td>['1633648433507573763']</td>\n",
       "      <td>2023-03-09T01:58:32.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17180761.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1633648424569679872</td>\n",
       "      <td>en</td>\n",
       "      <td>RT @TheRickWilson: They're captives of in the ...</td>\n",
       "      <td>1633648424569679872</td>\n",
       "      <td>899686918719381506</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633530595572842...</td>\n",
       "      <td>['1633648424569679872']</td>\n",
       "      <td>2023-03-09T01:58:30.000Z</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 reply_settings                   id lang  \\\n",
       "0           0       everyone  1633648438993883136   en   \n",
       "1           1       everyone  1633648437798522881   en   \n",
       "2           2       everyone  1633648433977335808   en   \n",
       "3           3       everyone  1633648433507573763   en   \n",
       "4           4       everyone  1633648424569679872   en   \n",
       "\n",
       "                                                text      conversation_id  \\\n",
       "0  RT @GabiNga1: @keith0sta @827js @1mir_r @45tf5...  1633648438993883136   \n",
       "1  RT @OccupyDemocrats: BREAKING: MAGA Gov. Sarah...  1633648437798522881   \n",
       "2  RT @OccupyDemocrats: BREAKING: MAGA Gov. Sarah...  1633648433977335808   \n",
       "3  @ybarrap We demand justice when cops shooting ...  1633564967164100615   \n",
       "4  RT @TheRickWilson: They're captives of in the ...  1633648424569679872   \n",
       "\n",
       "             author_id                                  referenced_tweets  \\\n",
       "0  1298715879673274370  [{'type': 'retweeted', 'id': '1633505762881282...   \n",
       "1            615777223  [{'type': 'retweeted', 'id': '1633546143337680...   \n",
       "2  1393026118303854594  [{'type': 'retweeted', 'id': '1633546143337680...   \n",
       "3            739248656  [{'type': 'replied_to', 'id': '163356496716410...   \n",
       "4   899686918719381506  [{'type': 'retweeted', 'id': '1633530595572842...   \n",
       "\n",
       "    edit_history_tweet_ids                created_at  \\\n",
       "0  ['1633648438993883136']  2023-03-09T01:58:34.000Z   \n",
       "1  ['1633648437798522881']  2023-03-09T01:58:33.000Z   \n",
       "2  ['1633648433977335808']  2023-03-09T01:58:33.000Z   \n",
       "3  ['1633648433507573763']  2023-03-09T01:58:32.000Z   \n",
       "4  ['1633648424569679872']  2023-03-09T01:58:30.000Z   \n",
       "\n",
       "   public_metrics.retweet_count  public_metrics.reply_count  \\\n",
       "0                           106                           0   \n",
       "1                          2300                           0   \n",
       "2                          2300                           0   \n",
       "3                             0                           0   \n",
       "4                           151                           0   \n",
       "\n",
       "   public_metrics.like_count  public_metrics.quote_count  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   public_metrics.impression_count  in_reply_to_user_id geo.place_id  \n",
       "0                                0                  NaN          NaN  \n",
       "1                                0                  NaN          NaN  \n",
       "2                                0                  NaN          NaN  \n",
       "3                                0           17180761.0          NaN  \n",
       "4                                0                  NaN          NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_json('maga_project_tweets.2023-03-08_21.15.55.808461.json')\n",
    "new_df.head()\n",
    "\n",
    "other_df = pd.read_csv('maga_project_tweets.2023-03-08_20.58.51.129896.tsv', delimiter='\\t')\n",
    "other_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-standing",
   "metadata": {},
   "source": [
    "# References and Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-surgery",
   "metadata": {},
   "source": [
    "#### References Used\n",
    "- [Towards Data Science Twitter API v2 Post](https://towardsdatascience.com/an-extensive-guide-to-collecting-tweets-from-twitter-api-v2-for-academic-research-using-python-3-518fcb71df2a)\n",
    "- [Twitter developer Recent API docs](https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent#tab1)\n",
    "- [Building Queries API 2 docs](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query)\n",
    "- [Twitter Dev API - enriched tweet objects](https://developer.twitter.com/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects/tweet)\n",
    "- [Recent search params](https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent)\n",
    "- [Stack Overflow, avoiding truncation](https://stackoverflow.com/questions/38717816/twitter-api-text-field-value-is-truncated)\n",
    "\n",
    "#### URL/Query builder\n",
    "\n",
    "- [Building Queries API 2 docs](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query)\n",
    "- [Twitter Dev API](https://developer.twitter.com/en/docs/twitter-api/enterprise/data-dictionary/native-enriched-objects/tweet)\n",
    "- [Recent search params](https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent)\n",
    "- avoid truncation: https://stackoverflow.com/questions/38717816/twitter-api-text-field-value-is-truncated\n",
    "- `(400, '{\"errors\":[{\"parameters\":{\"tweet.truncated\":[\"false\"]},\"message\":\"The query parameter [tweet.truncated] is not one of [query,start_time,end_time,since_id,until_id,max_results,next_token,pagination_token,sort_order,expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields]\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}')`\n",
    "\n",
    "#### Overcoming API Limitation\n",
    "\n",
    "- [Official twitter limits documentation](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/faq#:~:text=900%20requests%2F15%2Dmin%20window,%2Dhour%20window%20(application%20level))\n",
    "\n",
    "I have found two ways to get more than the 100 tweets allowed in a single request.  \n",
    "\n",
    "1. `my_response['meta']['next_token']` - Control for pagination, when more than a single page of tweets are available within a response.  This is passed in with the request as one of the params [gist](https://gist.githubusercontent.com/AndrewEdward37/8309d5701af8b5414498f60aafd68a5d/raw/d7fbf33a61d58943348deb3a20d94284c4deffc4/connect.py): \n",
    "```\n",
    "params['next_token'] = next_token\n",
    "responose = requests.request(\"GET\", url, headers=headers, params=parms)\n",
    "```\n",
    "\n",
    "1. Windowing over time ranges using `start_time` and `end_time` in query parameters.  Type should be ISO 8601 date, i.e. `YYYY-MM-DDTHH:mm:ssZ`.  This sets the newest, most recent UTC timestap to which the Tweets will be provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-adaptation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
