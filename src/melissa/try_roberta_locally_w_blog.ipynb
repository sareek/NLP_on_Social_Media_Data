{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84cacb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/mcirtain/miniconda3/envs/nlp/bin/python\n"
     ]
    }
   ],
   "source": [
    "my_env = !which python  # MUST RUN ON NLP env (for pytorch)\n",
    "print(my_env[0])\n",
    "assert '/nlp/' in my_env[0], 'Wrong conda env!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5ec8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "from urllib.request import urlopen\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as si\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4f0fab7-5b52-4bd6-a87a-826b47bd7a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url_chris = 'https://raw.githubusercontent.com/sareek/NLP_on_Social_Media_Data/main/data/%23chrisrocklive_project_tweets.2023-03-09_17.16.18.676751.json'\n",
    "# #url= 'https://raw.githubusercontent.com/sareek/NLP_on_Social_Media_Data/main/data/project_data.2023-03-11_13.11.55.783862.json'\n",
    "# df = pd.read_json(url_chris)\n",
    "# df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12a02f75-5ec7-4fab-9422-45de0fd8bd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92c2aac8-227d-4acc-828c-ad7d1d12b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "468909f4-d68d-4aa5-889e-4fd50bb479a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sia = si()\n",
    "# df['polarity_score'] = df.text.apply(lambda x: sia.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00a36139-ee0d-45b5-a4d1-19a4a20ed0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_polar = df[['text','polarity_score']].copy()\n",
    "# df_polar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75bf656f-24f8-4f5d-8151-d3ad38f283e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_polar.values[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58acd91f-490e-4df0-8286-453b9e2fe89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame(df, columns = [\"text\", \"public_metrics.retweet_count\", \"public_metrics.reply_count\",\t\"public_metrics.like_count\", \"public_metrics.quote_count\", \"public_metrics.impression_count\", 'polarity_score'])\n",
    "\n",
    "# df1 = df1.rename(columns= {\"public_metrics.retweet_count\":'retweet', \"public_metrics.reply_count\":\"reply\",\t\"public_metrics.like_count\":\"like\", \"public_metrics.quote_count\":'quote', \"public_metrics.impression_count\":\"impression\"})\n",
    "# df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0175202b-137f-4544-8447-4ea8cc93d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_like = df1.sort_values(\"like\", ascending = False)\n",
    "# df_like = df_like.head(300)\n",
    "# df_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a48961d-699f-4e0a-99a8-c70b540bb004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_retweet = df1.sort_values(\"retweet\", ascending = False)\n",
    "# df_retweet = df_retweet.head(300)\n",
    "# df_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58ed0840-e23f-4dcc-b406-876caa666487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0396, 0.3243, 0.4825],\n",
      "        [0.2434, 0.1244, 0.8184],\n",
      "        [0.5320, 0.4462, 0.9252],\n",
      "        [0.6833, 0.1960, 0.6324],\n",
      "        [0.4310, 0.2436, 0.1119]])\n"
     ]
    }
   ],
   "source": [
    "# verification\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a3650ea-edcd-4062-9ad4-621dc7e7d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mcirtain/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.cluster import KMeans\n",
    "nltk.download('stopwords')\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "logging.basicConfig(format= '%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import multiprocessing #import process\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b44c2-2ee6-4aed-b294-0051e1bd804d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6506d9c5-9e89-4cc1-a9df-ae9716c5963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30611, 37)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/sareek/NLP_on_Social_Media_Data/main/data/normalized_annotated_all_2023-04-07_12.43.49.255973.tsv'\n",
    "\n",
    "df = pd.read_csv(url, sep='\\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c58badbd-5519-49dc-a7e5-44ee33e3631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fix the following block...\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    #text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    #text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b89dd40-1f7f-4f90-ac07-f114fbb1d28b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "# BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "# STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# def clean_text(text):\n",
    "#     \"\"\"\n",
    "#         text: a string\n",
    "        \n",
    "#         return: modified initial string\n",
    "#     \"\"\"\n",
    "#     text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "#     text = text.lower() # lowercase text\n",
    "#     text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "#     text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "#     #text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "#     return text\n",
    "    \n",
    "# df['text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e24b8-7994-470c-9f04-c6602f89a7c0",
   "metadata": {},
   "source": [
    "### Need Help I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "86e41097-5c92-463a-8cd0-f87b5b7437e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Try to fix next cell:\n",
    "# from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "# \"\"\"\n",
    "# Repo id must use alphanumeric chars \n",
    "# or '-', '_', '.', \n",
    "# '--' and '..' are forbidden, \n",
    "# '-' and '.' cannot start or end the name, \n",
    "# max length is 96: '/twitter-roberta-base-sentiment'.\n",
    "# \"\"\"\n",
    "# MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c836873d-6ef7-4f3b-89f1-46aa031780b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "# #MODEL = f\"/twitter-roberta-base-{task}\"  # mc change\n",
    "# MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9daccae7-7ce8-4829-b11c-edbb993bfa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Good night ðŸ˜Š\"\n",
    "# tweet = preprocess(text)\n",
    "# print(f'preprocessed: {tweet}')\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# print(f'Encoded input: {encoded_input}')\n",
    "# output = model(**encoded_input)\n",
    "# print(f'output: {output}')\n",
    "# scores = output[0][0].detach().numpy()\n",
    "# print(f'scores: {scores}')\n",
    "# scores = softmax(scores)\n",
    "# print(f'softmax scores: {scores}')\n",
    "# rankiing = np.argsort(scores)\n",
    "# print(f'ranking: {ranking}')\n",
    "# ranking = ranking[:: -1]\n",
    "# print(f'ranking: {ranking}')\n",
    "# for i in range(scores.shape[0]):\n",
    "#     print(f'i: {i}')\n",
    "#     l = labels[ranking[i]]\n",
    "#     print(f'label l: {l}')\n",
    "#     s = scores[ranking[i]]\n",
    "#     print(f'score s: {s}')\n",
    "    \n",
    "# print(f\"tweet : {tweet} {i+1}) {l} {np.round(float(s), 4)}\")   ##### WARNING - Not consistent\n",
    "\n",
    "# row = {'text' : tweet, l: [np.round(float(s),4)]}  ##### WARNING - Not consistent\n",
    "# print(f'row: {row}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa604c5a-0df7-4441-91d2-e0f6f62ff2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Good night ðŸ˜Š\"\n",
    "# tweet = preprocess(text)\n",
    "# print(f'preprocessed: {tweet}')\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# print(f'Encoded input: {encoded_input}')\n",
    "# output = model(**encoded_input)\n",
    "# print(f'output: {output}')\n",
    "# scores = output[0][0].detach().numpy()\n",
    "# print(f'scores: {scores}')\n",
    "# scores = softmax(scores)\n",
    "# print(f'softmax scores: {scores}')\n",
    "# print(f'Max score and location:', scores.max(), scores.argmax())\n",
    "# sentiments = ['negative', 'neutral', 'positive']\n",
    "# print(f'\\nRoBERTa Prediction: {sentiments[scores.argmax()]}, Probability: {scores.max()}')\n",
    "# rankiing = np.argsort(scores)\n",
    "# print(f'ranking: {ranking}')\n",
    "# ranking = ranking[:: -1]\n",
    "# print(f'ranking: {ranking}')\n",
    "# for i in range(scores.shape[0]):\n",
    "#     print(f'i: {i}')\n",
    "#     l = labels[ranking[i]]\n",
    "#     print(f'label l: {l}')\n",
    "#     s = scores[ranking[i]]\n",
    "#     print(f'score s: {s}')\n",
    "    \n",
    "# # print(f\"tweet : {tweet} {i+1}) {l} {np.round(float(s), 4)}\")   ##### WARNING - Not consistent\n",
    "\n",
    "# # row = {'text' : tweet, l: [np.round(float(s),4)]}  ##### WARNING - Not consistent\n",
    "# # print(f'row: {row}')\n",
    "# row = {'text': tweet, sentiments[scores.argmax()]: [np.round(scores.max(),4)]}\n",
    "# print(f'row: {row}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065df17-e38e-4037-83a0-0f21aea39a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a99cc9aa-6ac3-42cf-8649-3d865cbafd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df columns: ['neg', 'neu', 'pos']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_textblob_Subjectivity</th>\n",
       "      <th>normalized_vader_Polarity</th>\n",
       "      <th>normalized_vader_Subjectivity</th>\n",
       "      <th>normalized_AFINN_scores</th>\n",
       "      <th>normalized_SentiWordNet_scores</th>\n",
       "      <th>our_label</th>\n",
       "      <th>annotator</th>\n",
       "      <th>roberta_content</th>\n",
       "      <th>roberta_polarity</th>\n",
       "      <th>roberta_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1633954063934009344</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:13:00+00:00</td>\n",
       "      <td>rt  infantry_bucky hes lucky a #chrisrocklive ...</td>\n",
       "      <td>RT @Infantry_bucky: Heâ€™s lucky a #ChrisRockLiv...</td>\n",
       "      <td>1519164980582653952</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633938373529292...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.176602</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @user Heâ€™s lucky a #ChrisRockLive was the w...</td>\n",
       "      <td>-0.635149</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1633954058212876288</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:12:59+00:00</td>\n",
       "      <td>rt  1_ofakindnocap chris rock we all been chea...</td>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: â€œwe all been c...</td>\n",
       "      <td>21575184</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217017</td>\n",
       "      <td>0.529018</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @user Chris Rock: â€œwe all been cheated on.....</td>\n",
       "      <td>-0.635149</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1633951267423768576</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:01:54+00:00</td>\n",
       "      <td>rt  1_ofakindnocap chris rock we all been chea...</td>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: â€œwe all been c...</td>\n",
       "      <td>360633018</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217017</td>\n",
       "      <td>0.529018</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @user Chris Rock: â€œwe all been cheated on.....</td>\n",
       "      <td>-0.635149</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1633950853626318848</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:15+00:00</td>\n",
       "      <td>rt  rolandsmartin working out and watching the...</td>\n",
       "      <td>RT @rolandsmartin: Working out and watching th...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632825595473149...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @user Working out and watching the @user @u...</td>\n",
       "      <td>0.388473</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1633950824664645632</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:08+00:00</td>\n",
       "      <td>rt  rolandsmartin workout done ill have a few ...</td>\n",
       "      <td>RT @rolandsmartin: Workout done. Iâ€™ll have a f...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632833853021728...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.219866</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @user Workout done. Iâ€™ll have a few comment...</td>\n",
       "      <td>0.168381</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0      conversation_id lang reply_settings   \n",
       "0             0           0  1633954063934009344   en       everyone  \\\n",
       "1             1           1  1633954058212876288   en       everyone   \n",
       "2             2           2  1633951267423768576   en       everyone   \n",
       "3             3           3  1633950853626318848   en       everyone   \n",
       "4             4           4  1633950824664645632   en       everyone   \n",
       "\n",
       "                  created_at   \n",
       "0  2023-03-09 22:13:00+00:00  \\\n",
       "1  2023-03-09 22:12:59+00:00   \n",
       "2  2023-03-09 22:01:54+00:00   \n",
       "3  2023-03-09 22:00:15+00:00   \n",
       "4  2023-03-09 22:00:08+00:00   \n",
       "\n",
       "                                          clean_text   \n",
       "0  rt  infantry_bucky hes lucky a #chrisrocklive ...  \\\n",
       "1  rt  1_ofakindnocap chris rock we all been chea...   \n",
       "2  rt  1_ofakindnocap chris rock we all been chea...   \n",
       "3  rt  rolandsmartin working out and watching the...   \n",
       "4  rt  rolandsmartin workout done ill have a few ...   \n",
       "\n",
       "                                                text            author_id   \n",
       "0  RT @Infantry_bucky: Heâ€™s lucky a #ChrisRockLiv...  1519164980582653952  \\\n",
       "1  RT @1_ofakindnocap: Chris Rock: â€œwe all been c...             21575184   \n",
       "2  RT @1_ofakindnocap: Chris Rock: â€œwe all been c...            360633018   \n",
       "3  RT @rolandsmartin: Working out and watching th...  1547101103803830272   \n",
       "4  RT @rolandsmartin: Workout done. Iâ€™ll have a f...  1547101103803830272   \n",
       "\n",
       "                                   referenced_tweets  ...   \n",
       "0  [{'type': 'retweeted', 'id': '1633938373529292...  ...  \\\n",
       "1  [{'type': 'retweeted', 'id': '1632283297588948...  ...   \n",
       "2  [{'type': 'retweeted', 'id': '1632283297588948...  ...   \n",
       "3  [{'type': 'retweeted', 'id': '1632825595473149...  ...   \n",
       "4  [{'type': 'retweeted', 'id': '1632833853021728...  ...   \n",
       "\n",
       "   normalized_textblob_Subjectivity normalized_vader_Polarity   \n",
       "0                          0.527778                  0.176602  \\\n",
       "1                          0.000000                  0.217017   \n",
       "2                          0.000000                  0.217017   \n",
       "3                          0.535714                  0.702710   \n",
       "4                          0.535714                  0.702710   \n",
       "\n",
       "   normalized_vader_Subjectivity  normalized_AFINN_scores   \n",
       "0                       0.640625                 0.448980  \\\n",
       "1                       0.529018                 0.367347   \n",
       "2                       0.529018                 0.367347   \n",
       "3                       0.191964                 0.489796   \n",
       "4                       0.219866                 0.489796   \n",
       "\n",
       "   normalized_SentiWordNet_scores  our_label  annotator   \n",
       "0                        0.444444        NaN        NaN  \\\n",
       "1                        0.333333        NaN        NaN   \n",
       "2                        0.333333        NaN        NaN   \n",
       "3                        0.412698        NaN        NaN   \n",
       "4                        0.412698        NaN        NaN   \n",
       "\n",
       "                                     roberta_content  roberta_polarity   \n",
       "0  RT @user Heâ€™s lucky a #ChrisRockLive was the w...         -0.635149  \\\n",
       "1  RT @user Chris Rock: â€œwe all been cheated on.....         -0.635149   \n",
       "2  RT @user Chris Rock: â€œwe all been cheated on.....         -0.635149   \n",
       "3  RT @user Working out and watching the @user @u...          0.388473   \n",
       "4  RT @user Workout done. Iâ€™ll have a few comment...          0.168381   \n",
       "\n",
       "  roberta_sentiment  \n",
       "0          negative  \n",
       "1          negative  \n",
       "2          negative  \n",
       "3          positive  \n",
       "4           neutral  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.nn - following a blog I found for roberta...\n",
    "# https://medium.com/@amanabdulla296/sentiment-analysis-with-vader-and-twitter-roberta-2ede7fb78909\n",
    "\n",
    "\n",
    "# twitter-roberta-base-sentiment model works better with minimalistic amount of manipulation to the data\n",
    "# just let the model know that there is username http links\n",
    "# def preprocess_new(text):\n",
    "#     new_text = []\n",
    "#     for t in text.split(\" \"):\n",
    "#         t = \"@user\" if t.startswith(\"@\") and len(t) > 1 else t\n",
    "#         t = \"http\" if t.startswith(\"http\") else t\n",
    "#         new_text.append(t)\n",
    "#     return \" \".join(new_text)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# TEMPORARY: SHRINK DATA FOR FASTER EVAL\n",
    "# df = df.iloc[:10]\n",
    "# print(df.shape)\n",
    "    \n",
    "# apply the preprocessing functions to the content\n",
    "df[\"roberta_content\"] = df[\"text\"].apply(preprocess)\n",
    "# model, tokenizer and so on are located in the following repo\n",
    "model_path = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "# a function that takes text and model to calculate probability of each sentiment\n",
    "def sentiment_analyzer(text, model):\n",
    "    encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = np.round(softmax(scores), 2)\n",
    "    scores_dict = {\"neg\": scores[0], \"neu\": scores[1], \"pos\": scores[2]}\n",
    "    return scores_dict\n",
    "\n",
    "# apply the roberta function\n",
    "df[\"roberta_probabilities\"] = df[\"roberta_content\"].apply(sentiment_analyzer, model=roberta_model)\n",
    "\n",
    "# since roberta model returned probability of each sentiment as a dictionary\n",
    "# let's convert each probaility into separate column\n",
    "probabilities = df[\"roberta_probabilities\"].apply(pd.Series)\n",
    "df = df.join(probabilities, lsuffix='left', rsuffix='right')\n",
    "df = df.drop(\"roberta_probabilities\", axis=1)\n",
    "\n",
    "# now calculate the polarity for each text by:\n",
    "# first multiplying each probability to its weights (-1=> negative, 0=>neutral and +1=>positive)\n",
    "# then sum the values and pass through Tanh function to scale values from -1 up to +1\n",
    "# finally we can assign labels for each text, depending on the polarity, e.g. -1.0 until -0.25 negavite\n",
    "polarity_weights = torch.tensor([-1, 0, 1])\n",
    "print(f\"df columns: {[x for x in df.columns if 'neu' in x or 'neg' in x or 'pos' in x]}\")\n",
    "probs = torch.tensor(df[[\"neg\", \"neu\", \"pos\"]].values)\n",
    "polarity = polarity_weights * probs\n",
    "polarity = polarity.sum(dim=-1)\n",
    "polarity_scaled = nn.Tanh()(polarity)\n",
    "df[\"roberta_polarity\"] = polarity_scaled.numpy()\n",
    "df[\"roberta_sentiment\"] = pd.cut(df[\"roberta_polarity\"],\n",
    "    bins=[-1.0, -0.25, 0.25, 1.0],labels=[\"negative\", \"neutral\", \"positive\"],)\n",
    "df = df.drop([\"neu\", \"neg\", \"pos\"], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c37f581b-8dfc-41af-9326-312deea679ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can I announce when we're done?\n",
    "# import os\n",
    "# os.system(\"say 'hey google'\")\n",
    "# os.system(\"say 'broadcast'\")\n",
    "# os.system(\"say 'done running your roberta notebook'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "78fbb09d-cf61-4eaa-87d3-e62495daa3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.system(\"say 'hey google'\")\n",
    "# os.system(\"say 'broadcast'\")\n",
    "# os.system(\"say 'done running your roberta notebook'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0534b1ac-dc35-41f3-8177-80a870e2e7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # reimplementation...\n",
    "# text = \"Good night ðŸ˜Š\"\n",
    "# #sentiment_df = pd.DataFrame(columns = ['text'])\n",
    "# sentiments = ['negative', 'neutral', 'positive']\n",
    "\n",
    "# df['roberta_raw_negative'] = None\n",
    "# df['roberta_raw_neutral'] = None\n",
    "# df['roberta_raw_positive'] = None\n",
    "# df['roberta_label'] = None\n",
    "# df['roberta__neg_softmax_score'] = None\n",
    "# df['roberta__neut_softmax_score'] = None\n",
    "# df['roberta__pos_softmax_score'] = None\n",
    "# #for tweet in df['text']:\n",
    "# for idx, row in df.iterrows():\n",
    "#     # classify each tweet, row by row\n",
    "#     encoded_input = tokenizer(row['text'], return_tensors='pt')\n",
    "#     output = model(**encoded_input)\n",
    "#     scores = output[0][0].detach().numpy()\n",
    "    \n",
    "#     scores = softmax(scores)\n",
    "    \n",
    "#     # update our data\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_label'] = sentiments[scores.argmax()]\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_argmax'] = scores.max()\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_negative'] = scores[0]\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_neutral'] = scores[1]\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_positive'] = scores[2]\n",
    "    \n",
    "#     if idx % 500 == 0:\n",
    "#         print(f'Through {idx} rows')\n",
    "    \n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d5187-f69d-4b74-84de-ca68a5e67534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "82e4d8ec-a403-4b15-bc71-46f211091559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text = \"Good night ðŸ˜Š\"\n",
    "# sentiment_df = pd.DataFrame(columns = ['text'])\n",
    "\n",
    "# df['roberta_label'] = None\n",
    "# df['roberta_score'] = None\n",
    "# for tweet in df['text']:\n",
    "#   tweet = preprocess(tweet)\n",
    "\n",
    "#   encoded_input = tokenizer(text, return_tensors='pt')\n",
    "#   output = model(**encoded_input)\n",
    "#   scores = output[0][0].detach().numpy()\n",
    "#   scores = softmax(scores)\n",
    "\n",
    "\n",
    "\n",
    "#   ranking = np.argsort(scores)\n",
    "#   ranking = ranking[::-1]\n",
    "#   for i in range(scores.shape[0]):\n",
    "#     l = labels[ranking[i]]\n",
    "#     s = scores[ranking[i]]\n",
    "#     print(f\"tweet : {tweet} {i+1}) {l} {np.round(float(s), 4)}\")\n",
    "#     row = {'text' : tweet, l: [np.round(float(s),4)]}\n",
    "#     #Append row to the sentiment data frame\n",
    "#     sentiment_df = sentiment_df.append(row, ignore_index = True)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ed99cd4-3040-4ad2-9a55-11f9a2091eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we vectorize this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ff23b132-f57d-4477-83a7-921d308b2766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_textblob_Subjectivity</th>\n",
       "      <th>normalized_vader_Polarity</th>\n",
       "      <th>normalized_vader_Subjectivity</th>\n",
       "      <th>normalized_AFINN_scores</th>\n",
       "      <th>normalized_SentiWordNet_scores</th>\n",
       "      <th>our_label</th>\n",
       "      <th>annotator</th>\n",
       "      <th>roberta_content</th>\n",
       "      <th>roberta_polarity</th>\n",
       "      <th>roberta_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30608</th>\n",
       "      <td>30608</td>\n",
       "      <td>32288</td>\n",
       "      <td>1633873447897149440</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 16:52:40+00:00</td>\n",
       "      <td>rt  kajakallas 79 years ago soviet planes bomb...</td>\n",
       "      <td>RT @kajakallas: 79 years ago Soviet planes bom...</td>\n",
       "      <td>1250015178248290304</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633741101885542...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111724</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @user 79 years ago Soviet planes bombed Tal...</td>\n",
       "      <td>-0.691069</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30609</th>\n",
       "      <td>30609</td>\n",
       "      <td>32289</td>\n",
       "      <td>1633873447108632576</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 16:52:40+00:00</td>\n",
       "      <td>rt  sternenko today 4 civilians were killed by...</td>\n",
       "      <td>RT @sternenko: Today 4 civilians were killed b...</td>\n",
       "      <td>1495109228876468224</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633803881447604...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276121</td>\n",
       "      <td>0.393973</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @user Today 4 civilians were killed by russ...</td>\n",
       "      <td>-0.701374</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30610</th>\n",
       "      <td>30610</td>\n",
       "      <td>32290</td>\n",
       "      <td>1633873445154091008</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 16:52:39+00:00</td>\n",
       "      <td>rt  sunshinelove68 how did the us lose six of ...</td>\n",
       "      <td>RT @Sunshinelove68: ðŸ’¥How Did the U.S. Lose Six...</td>\n",
       "      <td>980084548376584192</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633861161144958...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104989</td>\n",
       "      <td>0.717634</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @user ðŸ’¥How Did the U.S. Lose Six Of its Nuc...</td>\n",
       "      <td>-0.735222</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0      conversation_id lang reply_settings   \n",
       "30608         30608       32288  1633873447897149440   en       everyone  \\\n",
       "30609         30609       32289  1633873447108632576   en       everyone   \n",
       "30610         30610       32290  1633873445154091008   en       everyone   \n",
       "\n",
       "                      created_at   \n",
       "30608  2023-03-09 16:52:40+00:00  \\\n",
       "30609  2023-03-09 16:52:40+00:00   \n",
       "30610  2023-03-09 16:52:39+00:00   \n",
       "\n",
       "                                              clean_text   \n",
       "30608  rt  kajakallas 79 years ago soviet planes bomb...  \\\n",
       "30609  rt  sternenko today 4 civilians were killed by...   \n",
       "30610  rt  sunshinelove68 how did the us lose six of ...   \n",
       "\n",
       "                                                    text            author_id   \n",
       "30608  RT @kajakallas: 79 years ago Soviet planes bom...  1250015178248290304  \\\n",
       "30609  RT @sternenko: Today 4 civilians were killed b...  1495109228876468224   \n",
       "30610  RT @Sunshinelove68: ðŸ’¥How Did the U.S. Lose Six...   980084548376584192   \n",
       "\n",
       "                                       referenced_tweets  ...   \n",
       "30608  [{'type': 'retweeted', 'id': '1633741101885542...  ...  \\\n",
       "30609  [{'type': 'retweeted', 'id': '1633803881447604...  ...   \n",
       "30610  [{'type': 'retweeted', 'id': '1633861161144958...  ...   \n",
       "\n",
       "       normalized_textblob_Subjectivity normalized_vader_Polarity   \n",
       "30608                               0.0                  0.111724  \\\n",
       "30609                               0.0                  0.276121   \n",
       "30610                               0.0                  0.104989   \n",
       "\n",
       "       normalized_vader_Subjectivity  normalized_AFINN_scores   \n",
       "30608                       0.357143                 0.367347  \\\n",
       "30609                       0.393973                 0.448980   \n",
       "30610                       0.717634                 0.367347   \n",
       "\n",
       "       normalized_SentiWordNet_scores  our_label  annotator   \n",
       "30608                        0.269841        NaN        NaN  \\\n",
       "30609                        0.428571        NaN        NaN   \n",
       "30610                        0.476190        NaN        NaN   \n",
       "\n",
       "                                         roberta_content  roberta_polarity   \n",
       "30608  RT @user 79 years ago Soviet planes bombed Tal...         -0.691069  \\\n",
       "30609  RT @user Today 4 civilians were killed by russ...         -0.701374   \n",
       "30610  RT @user ðŸ’¥How Did the U.S. Lose Six Of its Nuc...         -0.735222   \n",
       "\n",
       "      roberta_sentiment  \n",
       "30608          negative  \n",
       "30609          negative  \n",
       "30610          negative  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee5c2299-5614-4494-bf37-17552294a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../../data/roberta_on_chris.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "85584617-81b9-4177-a15d-9f9d99615ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Try to run on all of our data:\n",
    "# url = 'https://raw.githubusercontent.com/sareek/NLP_on_Social_Media_Data/main/data/normalized_annotated_all_2023-04-07_12.43.49.255973.tsv'\n",
    "\n",
    "# df = pd.read_csv(url, sep='\\t')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "639bdc8b-032d-46e7-adab-925ca1a6ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # reimplementation...\n",
    "# #text = \"Good night ðŸ˜Š\"\n",
    "# #sentiment_df = pd.DataFrame(columns = ['text'])\n",
    "# sentiments = ['negative', 'neutral', 'positive']\n",
    "\n",
    "# df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# df['roberta_negative'] = None\n",
    "# df['roberta_neutral'] = None\n",
    "# df['roberta_positive'] = None\n",
    "# df['roberta_label'] = None\n",
    "# df['roberta_score'] = None\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "#     # classify each tweet, row by row\n",
    "#     encoded_input = tokenizer(row['clean_text'], return_tensors='pt')\n",
    "#     output = model(**encoded_input)\n",
    "#     scores = output[0][0].detach().numpy()\n",
    "#     scores = softmax(scores)\n",
    "    \n",
    "#     # update our data\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_label'] = sentiments[scores.argmax()]\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_argmax'] = scores.max()\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_negative'] = scores[0]\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_neutral'] = scores[1]\n",
    "#     df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_positive'] = scores[2]\n",
    "    \n",
    "#     if idx % 500 == 0:\n",
    "#         print(f'Through {idx} rows')\n",
    "    \n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f24b44d1-eaea-410a-964b-01498cfd39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('roberta_all.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f9a041a-e6cf-4e77-b84b-0f07336964e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_json('../../data/roberta_all.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b5959dd7-2e1e-489b-9603-b2e748a4b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('../../data/roberta_polarity_scores_not_normalized_04162023.0743.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc41168-f5c2-4c46-8923-2f03adc1eed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
