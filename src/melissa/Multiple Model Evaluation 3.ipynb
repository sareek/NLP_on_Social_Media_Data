{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "atomic-scholarship",
   "metadata": {},
   "source": [
    "# Part III:  \n",
    "\n",
    "#### Fix fields\n",
    "- lost keyword and one other field; restore by inner merge on deduped conversation_id\n",
    "- evaluate fields with no analytical value and clean up (drop those w/o value).\n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "structured-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "opposite-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 melissacirtain  staff  17710489 Apr  2 21:51 combined_model_data_without_annotations_norm_2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  17888142 Apr  2 21:51 combined_model_data_all_norm_2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff    178306 Apr  2 21:51 combined_model_data_with_annotations_norm_2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  18067647 Apr  7 07:55 normalized_annotated_all_2023-04-07_07.55.28.945037_OBSOLETE.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  18083911 Apr  7 13:01 normalized_annotated_all_2023-04-07_12.43.49.255973.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  18083911 Apr  8 13:21 normalized_annotatted_all_2023-04-07_13.21.00.0000.tsv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ls -lrt ../../data | grep norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "proprietary-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30611, 37) Index(['Unnamed: 0', 'Unnamed: 0.1', 'conversation_id', 'lang',\n",
      "       'reply_settings', 'created_at', 'clean_text', 'text', 'author_id',\n",
      "       'referenced_tweets', 'id', 'edit_history_tweet_ids',\n",
      "       'public_metrics.retweet_count', 'public_metrics.reply_count',\n",
      "       'public_metrics.like_count', 'public_metrics.impression_count',\n",
      "       'in_reply_to_user_id', 'geo.place_id', 'withheld.copyright',\n",
      "       'withheld.country_codes', 'geo.coordinates.type',\n",
      "       'geo.coordinates.coordinates', 'textblob_Polarity',\n",
      "       'textblob_Subjectivity', 'vader_Polarity', 'vader_Subjectivity',\n",
      "       'AFINN_scores', 'AFINN_sentiments', 'SentiWordNet_scores',\n",
      "       'normalized_textblob_Polarity', 'normalized_textblob_Subjectivity',\n",
      "       'normalized_vader_Polarity', 'normalized_vader_Subjectivity',\n",
      "       'normalized_AFINN_scores', 'normalized_SentiWordNet_scores',\n",
      "       'our_label', 'annotator'],\n",
      "      dtype='object')\n",
      "\n",
      "Missing Fields: ['public_metrics.quote_count', 'keyword']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/normalized_annotatted_all_2023-04-07_13.21.00.0000.tsv', sep='\\t')\n",
    "print(df.shape, df.columns)\n",
    "\n",
    "# We lost keyword.  Are we missing anything else?\n",
    "keys_df = pd.read_json('../../data/project_data.2023-03-11_13.11.55.783862.json')\n",
    "print('\\nMissing Fields:', [x for x in keys_df.columns if x not in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-honey",
   "metadata": {},
   "source": [
    "### Recover lost fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "animal-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36581, 21)\n",
      "(30611, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30611"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(keys_df.shape)\n",
    "keys_df.drop_duplicates(['conversation_id'], keep='first', inplace=True)\n",
    "print(keys_df.shape)\n",
    "\n",
    "keys_df.conversation_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baking-emergency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30611, 37)\n",
      "(30611, 39)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_textblob_Polarity</th>\n",
       "      <th>normalized_textblob_Subjectivity</th>\n",
       "      <th>normalized_vader_Polarity</th>\n",
       "      <th>normalized_vader_Subjectivity</th>\n",
       "      <th>normalized_AFINN_scores</th>\n",
       "      <th>normalized_SentiWordNet_scores</th>\n",
       "      <th>our_label</th>\n",
       "      <th>annotator</th>\n",
       "      <th>keyword</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1633954063934009344</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:13:00+00:00</td>\n",
       "      <td>rt infantry bucky lucky chrisrocklive worse th...</td>\n",
       "      <td>RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...</td>\n",
       "      <td>1519164980582653952</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633938373529292...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480556</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.176602</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#chrisrocklive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1633954058212876288</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:12:59+00:00</td>\n",
       "      <td>rt ofakindnocap chris rock cheated never perso...</td>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>21575184</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217017</td>\n",
       "      <td>0.529018</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#chrisrocklive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1633951267423768576</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:01:54+00:00</td>\n",
       "      <td>rt ofakindnocap chris rock cheated never perso...</td>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>360633018</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217017</td>\n",
       "      <td>0.529018</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#chrisrocklive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1633950853626318848</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:15+00:00</td>\n",
       "      <td>rt rolandsmartin working watching chrisrock ne...</td>\n",
       "      <td>RT @rolandsmartin: Working out and watching th...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632825595473149...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#chrisrocklive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1633950824664645632</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:08+00:00</td>\n",
       "      <td>rt rolandsmartin workout done comment chrisroc...</td>\n",
       "      <td>RT @rolandsmartin: Workout done. I’ll have a f...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632833853021728...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.219866</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#chrisrocklive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1      conversation_id lang reply_settings  \\\n",
       "0           0             0  1633954063934009344   en       everyone   \n",
       "1           1             1  1633954058212876288   en       everyone   \n",
       "2           2             2  1633951267423768576   en       everyone   \n",
       "3           3             3  1633950853626318848   en       everyone   \n",
       "4           4             4  1633950824664645632   en       everyone   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2023-03-09 22:13:00+00:00   \n",
       "1  2023-03-09 22:12:59+00:00   \n",
       "2  2023-03-09 22:01:54+00:00   \n",
       "3  2023-03-09 22:00:15+00:00   \n",
       "4  2023-03-09 22:00:08+00:00   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  rt infantry bucky lucky chrisrocklive worse th...   \n",
       "1  rt ofakindnocap chris rock cheated never perso...   \n",
       "2  rt ofakindnocap chris rock cheated never perso...   \n",
       "3  rt rolandsmartin working watching chrisrock ne...   \n",
       "4  rt rolandsmartin workout done comment chrisroc...   \n",
       "\n",
       "                                                text            author_id  \\\n",
       "0  RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...  1519164980582653952   \n",
       "1  RT @1_ofakindnocap: Chris Rock: “we all been c...             21575184   \n",
       "2  RT @1_ofakindnocap: Chris Rock: “we all been c...            360633018   \n",
       "3  RT @rolandsmartin: Working out and watching th...  1547101103803830272   \n",
       "4  RT @rolandsmartin: Workout done. I’ll have a f...  1547101103803830272   \n",
       "\n",
       "                                   referenced_tweets  ...  \\\n",
       "0  [{'type': 'retweeted', 'id': '1633938373529292...  ...   \n",
       "1  [{'type': 'retweeted', 'id': '1632283297588948...  ...   \n",
       "2  [{'type': 'retweeted', 'id': '1632283297588948...  ...   \n",
       "3  [{'type': 'retweeted', 'id': '1632825595473149...  ...   \n",
       "4  [{'type': 'retweeted', 'id': '1632833853021728...  ...   \n",
       "\n",
       "   normalized_textblob_Polarity normalized_textblob_Subjectivity  \\\n",
       "0                      0.480556                         0.527778   \n",
       "1                      0.500000                         0.000000   \n",
       "2                      0.500000                         0.000000   \n",
       "3                      0.623377                         0.535714   \n",
       "4                      0.623377                         0.535714   \n",
       "\n",
       "   normalized_vader_Polarity  normalized_vader_Subjectivity  \\\n",
       "0                   0.176602                       0.640625   \n",
       "1                   0.217017                       0.529018   \n",
       "2                   0.217017                       0.529018   \n",
       "3                   0.702710                       0.191964   \n",
       "4                   0.702710                       0.219866   \n",
       "\n",
       "   normalized_AFINN_scores  normalized_SentiWordNet_scores  our_label  \\\n",
       "0                 0.448980                        0.444444        NaN   \n",
       "1                 0.367347                        0.333333        NaN   \n",
       "2                 0.367347                        0.333333        NaN   \n",
       "3                 0.489796                        0.412698        NaN   \n",
       "4                 0.489796                        0.412698        NaN   \n",
       "\n",
       "  annotator         keyword public_metrics.quote_count  \n",
       "0       NaN  #chrisrocklive                          0  \n",
       "1       NaN  #chrisrocklive                          0  \n",
       "2       NaN  #chrisrocklive                          0  \n",
       "3       NaN  #chrisrocklive                          0  \n",
       "4       NaN  #chrisrocklive                          0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get keywords back\n",
    "print(df.shape)\n",
    "df = df.merge(right=keys_df[['conversation_id', 'keyword', 'public_metrics.quote_count']], \n",
    "              how='left', \n",
    "              on='conversation_id')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-stack",
   "metadata": {},
   "source": [
    "### Which columns can we drop?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "everyday-department",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                          30611     \n",
      "Unnamed: 0.1                        30611     \n",
      "conversation_id                     30611     \n",
      "lang                                1         \n",
      "reply_settings                      3         \n",
      "created_at                          19444     \n",
      "clean_text                          12763     \n",
      "text                                12793     \n",
      "author_id                           25604     \n",
      "referenced_tweets                   9131      \n",
      "id                                  30610     \n",
      "edit_history_tweet_ids              30607     \n",
      "public_metrics.retweet_count        807       \n",
      "public_metrics.reply_count          17        \n",
      "public_metrics.like_count           79        \n",
      "public_metrics.impression_count     692       \n",
      "in_reply_to_user_id                 3025      \n",
      "geo.place_id                        101       \n",
      "withheld.copyright                  1         \n",
      "withheld.country_codes              6         \n",
      "geo.coordinates.type                1         \n",
      "geo.coordinates.coordinates         4         \n",
      "textblob_Polarity                   1376      \n",
      "textblob_Subjectivity               1247      \n",
      "vader_Polarity                      757       \n",
      "vader_Subjectivity                  687       \n",
      "AFINN_scores                        43        \n",
      "AFINN_sentiments                    3         \n",
      "SentiWordNet_scores                 79        \n",
      "normalized_textblob_Polarity        1148      \n",
      "normalized_textblob_Subjectivity    1247      \n",
      "normalized_vader_Polarity           757       \n",
      "normalized_vader_Subjectivity       687       \n",
      "normalized_AFINN_scores             43        \n",
      "normalized_SentiWordNet_scores      78        \n",
      "our_label                           3         \n",
      "annotator                           3         \n",
      "keyword                             8         \n",
      "public_metrics.quote_count          10        \n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    # \"\".join(word.ljust(col_width) for word in row)\n",
    "    print(c.ljust(35), str(df[c].nunique()).ljust(10))\n",
    "    #print(f\"{c: >25} {df[c].nunique: >20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dirty-aggregate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30611, 32) Index(['conversation_id', 'reply_settings', 'created_at', 'clean_text', 'text',\n",
      "       'author_id', 'referenced_tweets', 'edit_history_tweet_ids',\n",
      "       'public_metrics.retweet_count', 'public_metrics.reply_count',\n",
      "       'public_metrics.like_count', 'public_metrics.impression_count',\n",
      "       'in_reply_to_user_id', 'geo.coordinates.type',\n",
      "       'geo.coordinates.coordinates', 'textblob_Polarity',\n",
      "       'textblob_Subjectivity', 'vader_Polarity', 'vader_Subjectivity',\n",
      "       'AFINN_scores', 'AFINN_sentiments', 'SentiWordNet_scores',\n",
      "       'normalized_textblob_Polarity', 'normalized_textblob_Subjectivity',\n",
      "       'normalized_vader_Polarity', 'normalized_vader_Subjectivity',\n",
      "       'normalized_AFINN_scores', 'normalized_SentiWordNet_scores',\n",
      "       'our_label', 'annotator', 'keyword', 'public_metrics.quote_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df['withheld.country_codes'].value_counts() # number of different country codes, 46 rows total\n",
    "df['geo.place_id'].nunique()  # 101 unique, 126 rows total\n",
    "\n",
    "df.drop(['Unnamed: 0', 'Unnamed: 0.1',\n",
    "          'lang', 'id', 'withheld.copyright',\n",
    "          'withheld.country_codes', 'geo.place_id'],\n",
    "        inplace=True, axis=1)\n",
    "\n",
    "print(df.shape, df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-thumb",
   "metadata": {},
   "source": [
    "# Inter-annotator Agreement\n",
    "\n",
    "### Reference:\n",
    "https://psych.unl.edu/psycrs/handcomp/hckappa.PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "retired-immune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_textblob_Polarity</th>\n",
       "      <th>normalized_vader_Polarity</th>\n",
       "      <th>normalized_AFINN_scores</th>\n",
       "      <th>normalized_SentiWordNet_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30611.000000</td>\n",
       "      <td>30611.000000</td>\n",
       "      <td>30611.000000</td>\n",
       "      <td>30611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.530875</td>\n",
       "      <td>0.507008</td>\n",
       "      <td>0.485524</td>\n",
       "      <td>0.422334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.121679</td>\n",
       "      <td>0.225197</td>\n",
       "      <td>0.060486</td>\n",
       "      <td>0.061745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.396825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499164</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.649076</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized_textblob_Polarity  normalized_vader_Polarity  \\\n",
       "count                  30611.000000               30611.000000   \n",
       "mean                       0.530875                   0.507008   \n",
       "std                        0.121679                   0.225197   \n",
       "min                        0.000000                   0.000000   \n",
       "25%                        0.500000                   0.360800   \n",
       "50%                        0.500000                   0.499164   \n",
       "75%                        0.568182                   0.649076   \n",
       "max                        1.000000                   1.000000   \n",
       "\n",
       "       normalized_AFINN_scores  normalized_SentiWordNet_scores  \n",
       "count             30611.000000                    30611.000000  \n",
       "mean                  0.485524                        0.422334  \n",
       "std                   0.060486                        0.061745  \n",
       "min                   0.000000                        0.000000  \n",
       "25%                   0.448980                        0.396825  \n",
       "50%                   0.489796                        0.412698  \n",
       "75%                   0.510204                        0.444444  \n",
       "max                   1.000000                        1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_cols = ['normalized_textblob_Polarity','normalized_vader_Polarity',\n",
    "       'normalized_AFINN_scores', 'normalized_SentiWordNet_scores']\n",
    "#df.loc[df[score_cols] >= 0]\n",
    "df[score_cols].describe()  # make sure they're all centered at zero, yes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-society",
   "metadata": {},
   "source": [
    "For strictly > .5, (1583, 32); < .5, (3303, 32)\n",
    "\n",
    "For >= .5, (1753, 32); for <= .5, (12200, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "frank-bristol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3303, 32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\n",
    "    (df['normalized_textblob_Polarity'] < 0.5) &\n",
    "    (df['normalized_vader_Polarity'] < 0.5) &\n",
    "    (df['normalized_AFINN_scores'] < 0.5) &\n",
    "    (df['normalized_SentiWordNet_scores'] < 0.5)\n",
    "].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-density",
   "metadata": {},
   "source": [
    "### Found a correlation\n",
    "\n",
    "Looks like AFINN and vader are highly correlated.  Next, look at their inter-annotator agreement over 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "raising-brake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_textblob_Polarity</th>\n",
       "      <th>normalized_vader_Polarity</th>\n",
       "      <th>normalized_AFINN_scores</th>\n",
       "      <th>normalized_SentiWordNet_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normalized_textblob_Polarity</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440644</td>\n",
       "      <td>0.461542</td>\n",
       "      <td>0.377246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_vader_Polarity</th>\n",
       "      <td>0.440644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827546</td>\n",
       "      <td>0.390117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_AFINN_scores</th>\n",
       "      <td>0.461542</td>\n",
       "      <td>0.827546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_SentiWordNet_scores</th>\n",
       "      <td>0.377246</td>\n",
       "      <td>0.390117</td>\n",
       "      <td>0.388647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                normalized_textblob_Polarity  \\\n",
       "normalized_textblob_Polarity                        1.000000   \n",
       "normalized_vader_Polarity                           0.440644   \n",
       "normalized_AFINN_scores                             0.461542   \n",
       "normalized_SentiWordNet_scores                      0.377246   \n",
       "\n",
       "                                normalized_vader_Polarity  \\\n",
       "normalized_textblob_Polarity                     0.440644   \n",
       "normalized_vader_Polarity                        1.000000   \n",
       "normalized_AFINN_scores                          0.827546   \n",
       "normalized_SentiWordNet_scores                   0.390117   \n",
       "\n",
       "                                normalized_AFINN_scores  \\\n",
       "normalized_textblob_Polarity                   0.461542   \n",
       "normalized_vader_Polarity                      0.827546   \n",
       "normalized_AFINN_scores                        1.000000   \n",
       "normalized_SentiWordNet_scores                 0.388647   \n",
       "\n",
       "                                normalized_SentiWordNet_scores  \n",
       "normalized_textblob_Polarity                          0.377246  \n",
       "normalized_vader_Polarity                             0.390117  \n",
       "normalized_AFINN_scores                               0.388647  \n",
       "normalized_SentiWordNet_scores                        1.000000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[score_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "criminal-tower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textblob</th>\n",
       "      <th>vader</th>\n",
       "      <th>afinn</th>\n",
       "      <th>sentiwordnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>textblob</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440644</td>\n",
       "      <td>0.461542</td>\n",
       "      <td>0.377246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vader</th>\n",
       "      <td>0.440644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827546</td>\n",
       "      <td>0.390117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afinn</th>\n",
       "      <td>0.461542</td>\n",
       "      <td>0.827546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiwordnet</th>\n",
       "      <td>0.377246</td>\n",
       "      <td>0.390117</td>\n",
       "      <td>0.388647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              textblob     vader     afinn  sentiwordnet\n",
       "textblob      1.000000  0.440644  0.461542      0.377246\n",
       "vader         0.440644  1.000000  0.827546      0.390117\n",
       "afinn         0.461542  0.827546  1.000000      0.388647\n",
       "sentiwordnet  0.377246  0.390117  0.388647      1.000000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the above more printable/publishable\n",
    "temp_df = df[score_cols]\n",
    "temp_df.columns = ['textblob','vader','afinn','sentiwordnet']\n",
    "temp_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-aaron",
   "metadata": {},
   "source": [
    "### Cohen's Kappa at 0.5 boundary\n",
    "\n",
    "- Making this a binary classification about 0.5\n",
    "- Probability of same classification by chance = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "nearby-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_kappa_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "asian-familiar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553993980731224"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = (df['normalized_AFINN_scores'] > 0.5)\n",
    "y2 = (df['normalized_vader_Polarity'] > 0.5)\n",
    "\n",
    "cohen_kappa_score(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "isolated-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A: normalized_textblob_Polarity   Model B: normalized_vader_Polarity   0.2039724225700278\n",
      "\n",
      "Model A: normalized_textblob_Polarity   Model B: normalized_AFINN_scores   0.3937684070430598\n",
      "\n",
      "Model A: normalized_textblob_Polarity   Model B: normalized_SentiWordNet_scores   0.19771060946960928\n",
      "\n",
      "Model A: normalized_vader_Polarity   Model B: normalized_AFINN_scores   0.5553993980731224\n",
      "\n",
      "Model A: normalized_vader_Polarity   Model B: normalized_SentiWordNet_scores   0.13575372460319957\n",
      "\n",
      "Model A: normalized_AFINN_scores   Model B: normalized_SentiWordNet_scores   0.21681130425251294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run cohen's kappa binary classifier eval over all model pairs\n",
    "\n",
    "from itertools import combinations\n",
    "for a, b in combinations(score_cols, 2):\n",
    "    y1 = (df[a] <= 0.5)\n",
    "    y2 = (df[b] <= 0.5)\n",
    "    score = cohen_kappa_score(y1, y2)\n",
    "    print(f'Model A: {a}   Model B: {b}   {score}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-recall",
   "metadata": {},
   "source": [
    "### How do vader and afinn agree with annotations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "convenient-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1935483870967742"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agreement on positives peek:\n",
    "afinn_agree_shape = df.loc[\n",
    "    (df['normalized_AFINN_scores'] > 0.5) &\n",
    "    (df['our_label'] == 'positive') \n",
    "].shape\n",
    "\n",
    "vader_agree_shape = df.loc[\n",
    "    (df['normalized_vader_Polarity'] > 0.5) &\n",
    "    (df['our_label'] == 'positive') \n",
    "].shape\n",
    "\n",
    "\n",
    "# agreement on negatives peek:\n",
    "afinn_agree_neg_shape = df.loc[\n",
    "    (df['normalized_AFINN_scores'] < 0.5) &\n",
    "    (df['our_label'] == 'negative') \n",
    "].shape\n",
    "\n",
    "vader_agree_neg_shape = df.loc[\n",
    "    (df['normalized_vader_Polarity'] < 0.5) &\n",
    "    (df['our_label'] == 'negative') \n",
    "].shape\n",
    "\n",
    "\n",
    "# Our shapes\n",
    "our_pos_shape = df.loc[df['our_label'] == 'positive'].shape\n",
    "our_pos_neut_shape = df.loc[\n",
    "    (df['our_label'] == 'positive') |\n",
    "    (df['our_label'] == 'neutral')\n",
    "].shape\n",
    "our_neg_shape = df.loc[df['our_label'] == 'negative'].shape\n",
    "\n",
    "\n",
    "afinn_agree_shape[0] / our_pos_shape[0]  # 0.4411764705882353\n",
    "vader_agree_shape[0] / our_pos_shape[0]  # 0.5294117647058824\n",
    "afinn_agree_neg_shape[0] / our_neg_shape[0]  # 0.7741935483870968\n",
    "vader_agree_shape[0] / our_neg_shape[0]  # 0.1935483870967742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "collaborative-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back up my data\n",
    "df.to_csv('../../data/normalized_annotatted_all_2023-04-08_20.20.00.0000.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "approved-victorian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 melissacirtain  staff   1699708 Mar 26 14:46 #chrisrocklive_project_tweets.2023-03-09_17.16.18.676751.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff   1697993 Mar 26 14:46 #tyrenichols_project_tweets.2023-03-09_19.25.43.435891.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff   1646638 Mar 26 14:46 chatgpt_project_tweets.2023-03-09_19.12.39.616553.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  14558535 Mar 26 14:46 deduplicated_tweets.2023-03-26_14.08.48.636120.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff    381596 Mar 26 14:46 maga_project_tweets.2023-03-08_22.25.11.437694.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff   1724693 Mar 26 14:46 obama_project_tweets.2023-03-08_22.36.15.226664.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff   1773671 Mar 26 14:46 russia_project_tweets.2023-03-08_22.51.51.710826.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff   1762648 Mar 26 14:46 statehood_project_tweets.2023-03-09_17.12.00.547177.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff   6029631 Mar 26 14:46 textblob_polarity.2023-03-26_14.35.07.210250.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff   1711914 Mar 26 14:46 ukraine_project_tweets.2023-03-09_12.09.04.774701.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff   6087102 Mar 26 14:46 vader_polarity.2023-03-26_14.38.52.858509.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     47359 Mar 30 20:44 anu_annotations.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     46365 Mar 30 20:44 sarik_annotations.tsv\n",
      "-rw-r--r--@ 1 melissacirtain  staff     45835 Apr  1 15:57 mel_annotations.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  13654018 Apr  1 21:33 deduplicated_tweets_by_conversation_id_.2023-04-01_16.15.21.235875.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     48069 Apr  2 13:55 Annotated_Anu.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  13930179 Apr  2 13:55 deduplicated_final_.2023-04-02_11.38.26.083972.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     47097 Apr  2 19:03 mel_annotations_REDO.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     47359 Apr  2 19:03 anu_annotations_REDO.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     46365 Apr  2 19:03 sarik_annotations_REDO.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     47097 Apr  2 19:36 mel_annotations_REDO_bak.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     46365 Apr  2 19:36 sarik_annotations_REDO_bak.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     47359 Apr  2 19:36 anu_annotations_REDO_bak.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     47937 Apr  2 19:39 mel_annotations_REDO_04022023.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff     47182 Apr  2 19:45 sarik_annotations_REDO_04022023.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  15050474 Apr  2 20:13 combined_model_data_without_annotations2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  15201846 Apr  2 20:13 combined_model_data_all_2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff    151852 Apr  2 20:13 combined_model_data_with_annotations_2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff    142860 Apr  2 20:18 combined_annotations_2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  17710489 Apr  2 21:51 combined_model_data_without_annotations_norm_2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  17888142 Apr  2 21:51 combined_model_data_all_norm_2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff    178306 Apr  2 21:51 combined_model_data_with_annotations_norm_2023-04-02_20.13.51.914670.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  18067647 Apr  7 07:55 normalized_annotated_all_2023-04-07_07.55.28.945037_OBSOLETE.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  18083911 Apr  7 13:01 normalized_annotated_all_2023-04-07_12.43.49.255973.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  18083911 Apr  8 13:21 normalized_annotatted_all_2023-04-07_13.21.00.0000.tsv\n",
      "-rw-r--r--  1 melissacirtain  staff  17468314 Apr  8 20:20 normalized_annotatted_all_2023-04-08_20.20.00.0000.tsv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# Random forest classifier?\n",
    "\n",
    "ls -lrt ../../data/ | grep .tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "meaningful-invention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>...</th>\n",
       "      <th>AFINN_sentiments</th>\n",
       "      <th>SentiWordNet_scores</th>\n",
       "      <th>normalized_textblob_Polarity</th>\n",
       "      <th>normalized_textblob_Subjectivity</th>\n",
       "      <th>normalized_vader_Polarity</th>\n",
       "      <th>normalized_vader_Subjectivity</th>\n",
       "      <th>normalized_AFINN_scores</th>\n",
       "      <th>normalized_SentiWordNet_scores</th>\n",
       "      <th>our_label</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>1633724515212742656</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 07:00:52+00:00</td>\n",
       "      <td>rt netflix chrisrocklive tonight pm et pm pt m...</td>\n",
       "      <td>RT @netflix: #ChrisRockLive TONIGHT at 10pm ET...</td>\n",
       "      <td>2348520354</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1631421624359739...</td>\n",
       "      <td>...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623918</td>\n",
       "      <td>0.468254</td>\n",
       "      <td>0.781464</td>\n",
       "      <td>0.364955</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>286</td>\n",
       "      <td>1633637250419367936</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 01:14:06+00:00</td>\n",
       "      <td>must read important notice different fixed mat...</td>\n",
       "      <td>YOU MUST READ  ‼️‼️‼️‼️\\nIMPORTANT NOTICE DIFF...</td>\n",
       "      <td>1631666639862132736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.601621</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>neutral</td>\n",
       "      <td>melissa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>360</td>\n",
       "      <td>1633586187700150272</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-08 21:51:12+00:00</td>\n",
       "      <td>rt netflixisajoke shout ohsnapjbsmoove flying ...</td>\n",
       "      <td>RT @NetflixIsAJoke: Shout out to @ohsnapjbsmoo...</td>\n",
       "      <td>852279096310546432</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633573306157916...</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>positive</td>\n",
       "      <td>anu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1      conversation_id lang reply_settings  \\\n",
       "185         185           186  1633724515212742656   en       everyone   \n",
       "285         285           286  1633637250419367936   en       everyone   \n",
       "359         359           360  1633586187700150272   en       everyone   \n",
       "\n",
       "                    created_at  \\\n",
       "185  2023-03-09 07:00:52+00:00   \n",
       "285  2023-03-09 01:14:06+00:00   \n",
       "359  2023-03-08 21:51:12+00:00   \n",
       "\n",
       "                                            clean_text  \\\n",
       "185  rt netflix chrisrocklive tonight pm et pm pt m...   \n",
       "285  must read important notice different fixed mat...   \n",
       "359  rt netflixisajoke shout ohsnapjbsmoove flying ...   \n",
       "\n",
       "                                                  text            author_id  \\\n",
       "185  RT @netflix: #ChrisRockLive TONIGHT at 10pm ET...           2348520354   \n",
       "285  YOU MUST READ  ‼️‼️‼️‼️\\nIMPORTANT NOTICE DIFF...  1631666639862132736   \n",
       "359  RT @NetflixIsAJoke: Shout out to @ohsnapjbsmoo...   852279096310546432   \n",
       "\n",
       "                                     referenced_tweets  ...  AFINN_sentiments  \\\n",
       "185  [{'type': 'retweeted', 'id': '1631421624359739...  ...          negative   \n",
       "285                                                NaN  ...          positive   \n",
       "359  [{'type': 'retweeted', 'id': '1633573306157916...  ...           neutral   \n",
       "\n",
       "    SentiWordNet_scores  normalized_textblob_Polarity  \\\n",
       "185                 0.0                      0.623918   \n",
       "285                 1.0                      0.583333   \n",
       "359                 0.0                      0.500000   \n",
       "\n",
       "     normalized_textblob_Subjectivity  normalized_vader_Polarity  \\\n",
       "185                          0.468254                   0.781464   \n",
       "285                          0.600000                   0.601621   \n",
       "359                          0.000000                   0.702710   \n",
       "\n",
       "     normalized_vader_Subjectivity  normalized_AFINN_scores  \\\n",
       "185                       0.364955                 0.469388   \n",
       "285                       0.107143                 0.530612   \n",
       "359                       0.191964                 0.489796   \n",
       "\n",
       "    normalized_SentiWordNet_scores  our_label annotator  \n",
       "185                       0.412698    neutral       anu  \n",
       "285                       0.539683    neutral   melissa  \n",
       "359                       0.412698   positive       anu  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../../data/normalized_annotated_all_2023-04-07_12.43.49.255973.tsv', delimiter='\\t')\n",
    "test_df.columns\n",
    "test_df.loc[~test_df['our_label'].isna()].head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
