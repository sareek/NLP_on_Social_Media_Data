{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cacb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mcirtain/miniconda3/envs/nlp/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python  # MUST RUN ON NLP env (for pytorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ec8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "from urllib.request import urlopen\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as si\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f0fab7-5b52-4bd6-a87a-826b47bd7a8d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5070 entries, 0 to 5069\n",
      "Data columns (total 18 columns):\n",
      " #   Column                           Non-Null Count  Dtype              \n",
      "---  ------                           --------------  -----              \n",
      " 0   conversation_id                  5070 non-null   int64              \n",
      " 1   lang                             5070 non-null   object             \n",
      " 2   reply_settings                   5070 non-null   object             \n",
      " 3   created_at                       5070 non-null   datetime64[ns, UTC]\n",
      " 4   text                             5070 non-null   object             \n",
      " 5   author_id                        5070 non-null   int64              \n",
      " 6   referenced_tweets                4708 non-null   object             \n",
      " 7   id                               5070 non-null   int64              \n",
      " 8   edit_history_tweet_ids           5070 non-null   object             \n",
      " 9   public_metrics.retweet_count     5070 non-null   int64              \n",
      " 10  public_metrics.reply_count       5070 non-null   int64              \n",
      " 11  public_metrics.like_count        5070 non-null   int64              \n",
      " 12  public_metrics.quote_count       5070 non-null   int64              \n",
      " 13  public_metrics.impression_count  5070 non-null   int64              \n",
      " 14  in_reply_to_user_id              77 non-null     float64            \n",
      " 15  geo.place_id                     25 non-null     object             \n",
      " 16  withheld.copyright               2 non-null      float64            \n",
      " 17  withheld.country_codes           2 non-null      object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(8), object(7)\n",
      "memory usage: 752.6+ KB\n"
     ]
    }
   ],
   "source": [
    "url_chris = 'https://raw.githubusercontent.com/sareek/NLP_on_Social_Media_Data/main/data/%23chrisrocklive_project_tweets.2023-03-09_17.16.18.676751.json'\n",
    "#url= 'https://raw.githubusercontent.com/sareek/NLP_on_Social_Media_Data/main/data/project_data.2023-03-11_13.11.55.783862.json'\n",
    "df = pd.read_json(url_chris)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a02f75-5ec7-4fab-9422-45de0fd8bd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/mcirtain/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c2aac8-227d-4acc-828c-ad7d1d12b646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "      <th>public_metrics.impression_count</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>geo.place_id</th>\n",
       "      <th>withheld.copyright</th>\n",
       "      <th>withheld.country_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1633954063934009344</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:13:00+00:00</td>\n",
       "      <td>RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...</td>\n",
       "      <td>1519164980582653952</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633938373529292...</td>\n",
       "      <td>1633954063934009344</td>\n",
       "      <td>[1633954063934009354]</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1633954058212876288</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:12:59+00:00</td>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>21575184</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>1633954058212876288</td>\n",
       "      <td>[1633954058212876289]</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1633951267423768576</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:01:54+00:00</td>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>360633018</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>1633951267423768576</td>\n",
       "      <td>[1633951267423768578]</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1633950853626318848</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:15+00:00</td>\n",
       "      <td>RT @rolandsmartin: Working out and watching th...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632825595473149...</td>\n",
       "      <td>1633950853626318848</td>\n",
       "      <td>[1633950853626318850]</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1633950824664645632</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:08+00:00</td>\n",
       "      <td>RT @rolandsmartin: Workout done. I’ll have a f...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632833853021728...</td>\n",
       "      <td>1633950824664645632</td>\n",
       "      <td>[1633950824664645634]</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       conversation_id lang reply_settings                created_at   \n",
       "0  1633954063934009344   en       everyone 2023-03-09 22:13:00+00:00  \\\n",
       "1  1633954058212876288   en       everyone 2023-03-09 22:12:59+00:00   \n",
       "2  1633951267423768576   en       everyone 2023-03-09 22:01:54+00:00   \n",
       "3  1633950853626318848   en       everyone 2023-03-09 22:00:15+00:00   \n",
       "4  1633950824664645632   en       everyone 2023-03-09 22:00:08+00:00   \n",
       "\n",
       "                                                text            author_id   \n",
       "0  RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...  1519164980582653952  \\\n",
       "1  RT @1_ofakindnocap: Chris Rock: “we all been c...             21575184   \n",
       "2  RT @1_ofakindnocap: Chris Rock: “we all been c...            360633018   \n",
       "3  RT @rolandsmartin: Working out and watching th...  1547101103803830272   \n",
       "4  RT @rolandsmartin: Workout done. I’ll have a f...  1547101103803830272   \n",
       "\n",
       "                                   referenced_tweets                   id   \n",
       "0  [{'type': 'retweeted', 'id': '1633938373529292...  1633954063934009344  \\\n",
       "1  [{'type': 'retweeted', 'id': '1632283297588948...  1633954058212876288   \n",
       "2  [{'type': 'retweeted', 'id': '1632283297588948...  1633951267423768576   \n",
       "3  [{'type': 'retweeted', 'id': '1632825595473149...  1633950853626318848   \n",
       "4  [{'type': 'retweeted', 'id': '1632833853021728...  1633950824664645632   \n",
       "\n",
       "  edit_history_tweet_ids  public_metrics.retweet_count   \n",
       "0  [1633954063934009354]                             8  \\\n",
       "1  [1633954058212876289]                           616   \n",
       "2  [1633951267423768578]                           616   \n",
       "3  [1633950853626318850]                            14   \n",
       "4  [1633950824664645634]                             8   \n",
       "\n",
       "   public_metrics.reply_count  public_metrics.like_count   \n",
       "0                           0                          0  \\\n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "\n",
       "   public_metrics.quote_count  public_metrics.impression_count   \n",
       "0                           0                                0  \\\n",
       "1                           0                                0   \n",
       "2                           0                                0   \n",
       "3                           0                                0   \n",
       "4                           0                                0   \n",
       "\n",
       "   in_reply_to_user_id geo.place_id  withheld.copyright withheld.country_codes  \n",
       "0                  NaN         None                 NaN                   None  \n",
       "1                  NaN         None                 NaN                   None  \n",
       "2                  NaN         None                 NaN                   None  \n",
       "3                  NaN         None                 NaN                   None  \n",
       "4                  NaN         None                 NaN                   None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "468909f4-d68d-4aa5-889e-4fd50bb479a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = si()\n",
    "df['polarity_score'] = df.text.apply(lambda x: sia.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a36139-ee0d-45b5-a4d1-19a4a20ed0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...</td>\n",
       "      <td>{'neg': 0.292, 'neu': 0.613, 'pos': 0.095, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>{'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>{'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @rolandsmartin: Working out and watching th...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @rolandsmartin: Workout done. I’ll have a f...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   \n",
       "0  RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...  \\\n",
       "1  RT @1_ofakindnocap: Chris Rock: “we all been c...   \n",
       "2  RT @1_ofakindnocap: Chris Rock: “we all been c...   \n",
       "3  RT @rolandsmartin: Working out and watching th...   \n",
       "4  RT @rolandsmartin: Workout done. I’ll have a f...   \n",
       "\n",
       "                                      polarity_score  \n",
       "0  {'neg': 0.292, 'neu': 0.613, 'pos': 0.095, 'co...  \n",
       "1  {'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...  \n",
       "2  {'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...  \n",
       "3  {'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'comp...  \n",
       "4  {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polar = df[['text','polarity_score']].copy()\n",
    "df_polar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75bf656f-24f8-4f5d-8151-d3ad38f283e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['RT @Infantry_bucky: He’s lucky a #ChrisRockLive was the worse thing that happened to him .. and he’s still crying !! What a strange charact…'\n",
      "  {'neg': 0.292, 'neu': 0.613, 'pos': 0.095, 'compound': -0.6988}]]\n"
     ]
    }
   ],
   "source": [
    "print(df_polar.values[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58acd91f-490e-4df0-8286-453b9e2fe89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet</th>\n",
       "      <th>reply</th>\n",
       "      <th>like</th>\n",
       "      <th>quote</th>\n",
       "      <th>impression</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.292, 'neu': 0.613, 'pos': 0.095, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @rolandsmartin: Working out and watching th...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @rolandsmartin: Workout done. I’ll have a f...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5065</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5066</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5067</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>RT @Callme_Tylor: Now this is funny!!!!!! @Mar...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5070 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  retweet  reply  like   \n",
       "0     RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...        8      0     0  \\\n",
       "1     RT @1_ofakindnocap: Chris Rock: “we all been c...      616      0     0   \n",
       "2     RT @1_ofakindnocap: Chris Rock: “we all been c...      616      0     0   \n",
       "3     RT @rolandsmartin: Working out and watching th...       14      0     0   \n",
       "4     RT @rolandsmartin: Workout done. I’ll have a f...        8      0     0   \n",
       "...                                                 ...      ...    ...   ...   \n",
       "5065  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "5066  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "5067  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "5068  RT @Callme_Tylor: Now this is funny!!!!!! @Mar...       90      0     0   \n",
       "5069  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "\n",
       "      quote  impression                                     polarity_score  \n",
       "0         0           0  {'neg': 0.292, 'neu': 0.613, 'pos': 0.095, 'co...  \n",
       "1         0           0  {'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...  \n",
       "2         0           0  {'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...  \n",
       "3         0           0  {'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'comp...  \n",
       "4         0           0  {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...  \n",
       "...     ...         ...                                                ...  \n",
       "5065      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "5066      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "5067      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "5068      0           0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "5069      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "\n",
       "[5070 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(df, columns = [\"text\", \"public_metrics.retweet_count\", \"public_metrics.reply_count\",\t\"public_metrics.like_count\", \"public_metrics.quote_count\", \"public_metrics.impression_count\", 'polarity_score'])\n",
    "\n",
    "df1 = df1.rename(columns= {\"public_metrics.retweet_count\":'retweet', \"public_metrics.reply_count\":\"reply\",\t\"public_metrics.like_count\":\"like\", \"public_metrics.quote_count\":'quote', \"public_metrics.impression_count\":\"impression\"})\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0175202b-137f-4544-8447-4ea8cc93d8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet</th>\n",
       "      <th>reply</th>\n",
       "      <th>like</th>\n",
       "      <th>quote</th>\n",
       "      <th>impression</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>#MeghanMarkle must be really worried about wha...</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>534</td>\n",
       "      <td>1</td>\n",
       "      <td>10103</td>\n",
       "      <td>{'neg': 0.168, 'neu': 0.832, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>If I slapped someone at work because I don’t l...</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>10629</td>\n",
       "      <td>{'neg': 0.102, 'neu': 0.768, 'pos': 0.131, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Shout out to @ohsnapjbsmoove for flying out to...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>26315</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.824, 'pos': 0.176, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>SHOCK! Chris Rock HELPED Samantha Markle's Law...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>5751</td>\n",
       "      <td>{'neg': 0.295, 'neu': 0.705, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>He’s lucky a #ChrisRockLive was the worse thin...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>832</td>\n",
       "      <td>{'neg': 0.302, 'neu': 0.599, 'pos': 0.099, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  retweet  reply  like   \n",
       "1153  #MeghanMarkle must be really worried about wha...       50     13   534  \\\n",
       "3918  If I slapped someone at work because I don’t l...        7     13   127   \n",
       "390   Shout out to @ohsnapjbsmoove for flying out to...        9      3    66   \n",
       "2261  SHOCK! Chris Rock HELPED Samantha Markle's Law...        8      3    53   \n",
       "25    He’s lucky a #ChrisRockLive was the worse thin...        8      7    32   \n",
       "...                                                 ...      ...    ...   ...   \n",
       "3239  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "3238  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "3237  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "3236  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "3235  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "\n",
       "      quote  impression                                     polarity_score  \n",
       "1153      1       10103  {'neg': 0.168, 'neu': 0.832, 'pos': 0.0, 'comp...  \n",
       "3918      1       10629  {'neg': 0.102, 'neu': 0.768, 'pos': 0.131, 'co...  \n",
       "390       1       26315  {'neg': 0.0, 'neu': 0.824, 'pos': 0.176, 'comp...  \n",
       "2261      1        5751  {'neg': 0.295, 'neu': 0.705, 'pos': 0.0, 'comp...  \n",
       "25        1         832  {'neg': 0.302, 'neu': 0.599, 'pos': 0.099, 'co...  \n",
       "...     ...         ...                                                ...  \n",
       "3239      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "3238      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "3237      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "3236      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "3235      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_like = df1.sort_values(\"like\", ascending = False)\n",
    "df_like = df_like.head(300)\n",
    "df_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a48961d-699f-4e0a-99a8-c70b540bb004",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet</th>\n",
       "      <th>reply</th>\n",
       "      <th>like</th>\n",
       "      <th>quote</th>\n",
       "      <th>impression</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>RT @sagesurge: Marlon Wayans roasting Chris Ro...</td>\n",
       "      <td>9130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  retweet  reply  like   \n",
       "5069  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0  \\\n",
       "2496  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "2484  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "4238  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "2487  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "...                                                 ...      ...    ...   ...   \n",
       "2831  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "2833  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "2834  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "2835  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "4172  RT @sagesurge: Marlon Wayans roasting Chris Ro...     9130      0     0   \n",
       "\n",
       "      quote  impression                                     polarity_score  \n",
       "5069      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "2496      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "2484      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "4238      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "2487      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "...     ...         ...                                                ...  \n",
       "2831      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "2833      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "2834      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "2835      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "4172      0           0  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...  \n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_retweet = df1.sort_values(\"retweet\", ascending = False)\n",
    "df_retweet = df_retweet.head(300)\n",
    "df_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ed0840-e23f-4dcc-b406-876caa666487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9737, 0.0740, 0.7321],\n",
      "        [0.5260, 0.4024, 0.4277],\n",
      "        [0.3952, 0.7998, 0.4132],\n",
      "        [0.1966, 0.7806, 0.4129],\n",
      "        [0.2772, 0.9962, 0.5291]])\n"
     ]
    }
   ],
   "source": [
    "# verification\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a3650ea-edcd-4062-9ad4-621dc7e7d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mcirtain/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.cluster import KMeans\n",
    "nltk.download('stopwords')\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "logging.basicConfig(format= '%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import multiprocessing #import process\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c58badbd-5519-49dc-a7e5-44ee33e3631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fix the following block...\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    #text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    #text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b89dd40-1f7f-4f90-ac07-f114fbb1d28b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m---> 18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/series.py:4631\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4522\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4523\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4528\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4530\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4630\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[23], line 11\u001b[0m, in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_text\u001b[39m(text):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m        text: a string\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m        \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m        return: modified initial string\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;66;03m# HTML decoding\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;66;03m# lowercase text\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     text \u001b[38;5;241m=\u001b[39m REPLACE_BY_SPACE_RE\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, text) \u001b[38;5;66;03m# replace REPLACE_BY_SPACE_RE symbols by space in text\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/bs4/__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    #text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e24b8-7994-470c-9f04-c6602f89a7c0",
   "metadata": {},
   "source": [
    "### Need Help I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86e41097-5c92-463a-8cd0-f87b5b7437e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try to fix next cell:\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "\"\"\"\n",
    "Repo id must use alphanumeric chars \n",
    "or '-', '_', '.', \n",
    "'--' and '..' are forbidden, \n",
    "'-' and '.' cannot start or end the name, \n",
    "max length is 96: '/twitter-roberta-base-sentiment'.\n",
    "\"\"\"\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c836873d-6ef7-4f3b-89f1-46aa031780b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c988846fed4826aa539c4fb276c520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "#MODEL = f\"/twitter-roberta-base-{task}\"  # mc change\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9daccae7-7ce8-4829-b11c-edbb993bfa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed: Good night 😊\n",
      "Encoded input: {'input_ids': tensor([[    0, 12350,   363, 17841, 27969,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "output: SequenceClassifierOutput(loss=None, logits=tensor([[-2.4362,  0.5167,  2.2755]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "scores: [-2.4362073   0.51666594  2.2755494 ]\n",
      "softmax scores: [0.00760987 0.14581212 0.84657806]\n",
      "ranking: [0 1 2]\n",
      "ranking: [2 1 0]\n",
      "i: 0\n",
      "label l: positive\n",
      "score s: 0.846578061580658\n",
      "i: 1\n",
      "label l: neutral\n",
      "score s: 0.14581212401390076\n",
      "i: 2\n",
      "label l: negative\n",
      "score s: 0.00760986702516675\n",
      "tweet : Good night 😊 3) negative 0.0076\n",
      "row: {'text': 'Good night 😊', 'negative': [0.0076]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Good night 😊\"\n",
    "tweet = preprocess(text)\n",
    "print(f'preprocessed: {tweet}')\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(f'Encoded input: {encoded_input}')\n",
    "output = model(**encoded_input)\n",
    "print(f'output: {output}')\n",
    "scores = output[0][0].detach().numpy()\n",
    "print(f'scores: {scores}')\n",
    "scores = softmax(scores)\n",
    "print(f'softmax scores: {scores}')\n",
    "rankiing = np.argsort(scores)\n",
    "print(f'ranking: {ranking}')\n",
    "ranking = ranking[:: -1]\n",
    "print(f'ranking: {ranking}')\n",
    "for i in range(scores.shape[0]):\n",
    "    print(f'i: {i}')\n",
    "    l = labels[ranking[i]]\n",
    "    print(f'label l: {l}')\n",
    "    s = scores[ranking[i]]\n",
    "    print(f'score s: {s}')\n",
    "    \n",
    "print(f\"tweet : {tweet} {i+1}) {l} {np.round(float(s), 4)}\")   ##### WARNING - Not consistent\n",
    "\n",
    "row = {'text' : tweet, l: [np.round(float(s),4)]}  ##### WARNING - Not consistent\n",
    "print(f'row: {row}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fa604c5a-0df7-4441-91d2-e0f6f62ff2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed: Good night 😊\n",
      "Encoded input: {'input_ids': tensor([[    0, 12350,   363, 17841, 27969,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "output: SequenceClassifierOutput(loss=None, logits=tensor([[-2.4362,  0.5167,  2.2755]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "scores: [-2.4362073   0.51666594  2.2755494 ]\n",
      "softmax scores: [0.00760987 0.14581212 0.84657806]\n",
      "Max score and location: 0.84657806 2\n",
      "\n",
      "RoBERTa Prediction: positive, Probability: 0.846578061580658\n",
      "ranking: [2 1 0]\n",
      "ranking: [0 1 2]\n",
      "i: 0\n",
      "label l: negative\n",
      "score s: 0.00760986702516675\n",
      "i: 1\n",
      "label l: neutral\n",
      "score s: 0.14581212401390076\n",
      "i: 2\n",
      "label l: positive\n",
      "score s: 0.846578061580658\n",
      "tweet : Good night 😊 3) positive 0.8466\n",
      "row: {'text': 'Good night 😊', 'positive': [0.8466]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Good night 😊\"\n",
    "tweet = preprocess(text)\n",
    "print(f'preprocessed: {tweet}')\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(f'Encoded input: {encoded_input}')\n",
    "output = model(**encoded_input)\n",
    "print(f'output: {output}')\n",
    "scores = output[0][0].detach().numpy()\n",
    "print(f'scores: {scores}')\n",
    "scores = softmax(scores)\n",
    "print(f'softmax scores: {scores}')\n",
    "print(f'Max score and location:', scores.max(), scores.argmax())\n",
    "sentiments = ['negative', 'neutral', 'positive']\n",
    "print(f'\\nRoBERTa Prediction: {sentiments[scores.argmax()]}, Probability: {scores.max()}')\n",
    "rankiing = np.argsort(scores)\n",
    "print(f'ranking: {ranking}')\n",
    "ranking = ranking[:: -1]\n",
    "print(f'ranking: {ranking}')\n",
    "for i in range(scores.shape[0]):\n",
    "    print(f'i: {i}')\n",
    "    l = labels[ranking[i]]\n",
    "    print(f'label l: {l}')\n",
    "    s = scores[ranking[i]]\n",
    "    print(f'score s: {s}')\n",
    "    \n",
    "# print(f\"tweet : {tweet} {i+1}) {l} {np.round(float(s), 4)}\")   ##### WARNING - Not consistent\n",
    "\n",
    "# row = {'text' : tweet, l: [np.round(float(s),4)]}  ##### WARNING - Not consistent\n",
    "# print(f'row: {row}')\n",
    "row = {'text': tweet, sentiments[scores.argmax()]: [np.round(scores.max(),4)]}\n",
    "print(f'row: {row}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0534b1ac-dc35-41f3-8177-80a870e2e7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Through 0 rows\n",
      "Through 500 rows\n",
      "Through 1000 rows\n",
      "Through 1500 rows\n",
      "Through 2000 rows\n",
      "Through 2500 rows\n",
      "Through 3000 rows\n",
      "Through 3500 rows\n",
      "Through 4000 rows\n",
      "Through 4500 rows\n",
      "Through 5000 rows\n",
      "CPU times: user 4min 29s, sys: 1min 25s, total: 5min 54s\n",
      "Wall time: 2min 55s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>...</th>\n",
       "      <th>geo.place_id</th>\n",
       "      <th>withheld.copyright</th>\n",
       "      <th>withheld.country_codes</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>roberta_label</th>\n",
       "      <th>roberta_score</th>\n",
       "      <th>roberta_negative</th>\n",
       "      <th>roberta_neutral</th>\n",
       "      <th>roberta_positive</th>\n",
       "      <th>roberta_argmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1633954063934009344</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:13:00+00:00</td>\n",
       "      <td>rt  infantry_bucky hes lucky a #chrisrocklive ...</td>\n",
       "      <td>1519164980582653952</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633938373529292...</td>\n",
       "      <td>1633954063934009344</td>\n",
       "      <td>[1633954063934009354]</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'neg': 0.292, 'neu': 0.613, 'pos': 0.095, 'co...</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0.730327</td>\n",
       "      <td>0.228264</td>\n",
       "      <td>0.041409</td>\n",
       "      <td>0.730327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1633954058212876288</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:12:59+00:00</td>\n",
       "      <td>rt  1_ofakindnocap chris rock we all been chea...</td>\n",
       "      <td>21575184</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>1633954058212876288</td>\n",
       "      <td>[1633954058212876289]</td>\n",
       "      <td>616</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0.875976</td>\n",
       "      <td>0.117147</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.875976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1633951267423768576</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:01:54+00:00</td>\n",
       "      <td>rt  1_ofakindnocap chris rock we all been chea...</td>\n",
       "      <td>360633018</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>1633951267423768576</td>\n",
       "      <td>[1633951267423768578]</td>\n",
       "      <td>616</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0.875976</td>\n",
       "      <td>0.117147</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.875976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1633950853626318848</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:15+00:00</td>\n",
       "      <td>rt  rolandsmartin working out and watching the...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632825595473149...</td>\n",
       "      <td>1633950853626318848</td>\n",
       "      <td>[1633950853626318850]</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'comp...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.686881</td>\n",
       "      <td>0.30526</td>\n",
       "      <td>0.686881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1633950824664645632</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:08+00:00</td>\n",
       "      <td>rt  rolandsmartin workout done ill have a few ...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632833853021728...</td>\n",
       "      <td>1633950824664645632</td>\n",
       "      <td>[1633950824664645634]</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.872722</td>\n",
       "      <td>0.116877</td>\n",
       "      <td>0.872722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       conversation_id lang reply_settings                created_at   \n",
       "0  1633954063934009344   en       everyone 2023-03-09 22:13:00+00:00  \\\n",
       "1  1633954058212876288   en       everyone 2023-03-09 22:12:59+00:00   \n",
       "2  1633951267423768576   en       everyone 2023-03-09 22:01:54+00:00   \n",
       "3  1633950853626318848   en       everyone 2023-03-09 22:00:15+00:00   \n",
       "4  1633950824664645632   en       everyone 2023-03-09 22:00:08+00:00   \n",
       "\n",
       "                                                text            author_id   \n",
       "0  rt  infantry_bucky hes lucky a #chrisrocklive ...  1519164980582653952  \\\n",
       "1  rt  1_ofakindnocap chris rock we all been chea...             21575184   \n",
       "2  rt  1_ofakindnocap chris rock we all been chea...            360633018   \n",
       "3  rt  rolandsmartin working out and watching the...  1547101103803830272   \n",
       "4  rt  rolandsmartin workout done ill have a few ...  1547101103803830272   \n",
       "\n",
       "                                   referenced_tweets                   id   \n",
       "0  [{'type': 'retweeted', 'id': '1633938373529292...  1633954063934009344  \\\n",
       "1  [{'type': 'retweeted', 'id': '1632283297588948...  1633954058212876288   \n",
       "2  [{'type': 'retweeted', 'id': '1632283297588948...  1633951267423768576   \n",
       "3  [{'type': 'retweeted', 'id': '1632825595473149...  1633950853626318848   \n",
       "4  [{'type': 'retweeted', 'id': '1632833853021728...  1633950824664645632   \n",
       "\n",
       "  edit_history_tweet_ids  public_metrics.retweet_count  ...  geo.place_id   \n",
       "0  [1633954063934009354]                             8  ...          None  \\\n",
       "1  [1633954058212876289]                           616  ...          None   \n",
       "2  [1633951267423768578]                           616  ...          None   \n",
       "3  [1633950853626318850]                            14  ...          None   \n",
       "4  [1633950824664645634]                             8  ...          None   \n",
       "\n",
       "   withheld.copyright  withheld.country_codes   \n",
       "0                 NaN                    None  \\\n",
       "1                 NaN                    None   \n",
       "2                 NaN                    None   \n",
       "3                 NaN                    None   \n",
       "4                 NaN                    None   \n",
       "\n",
       "                                      polarity_score  roberta_label   \n",
       "0  {'neg': 0.292, 'neu': 0.613, 'pos': 0.095, 'co...       negative  \\\n",
       "1  {'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...       negative   \n",
       "2  {'neg': 0.315, 'neu': 0.685, 'pos': 0.0, 'comp...       negative   \n",
       "3  {'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'comp...        neutral   \n",
       "4  {'neg': 0.0, 'neu': 0.863, 'pos': 0.137, 'comp...        neutral   \n",
       "\n",
       "  roberta_score  roberta_negative roberta_neutral roberta_positive   \n",
       "0          None          0.730327        0.228264         0.041409  \\\n",
       "1          None          0.875976        0.117147         0.006877   \n",
       "2          None          0.875976        0.117147         0.006877   \n",
       "3          None          0.007859        0.686881          0.30526   \n",
       "4          None          0.010401        0.872722         0.116877   \n",
       "\n",
       "  roberta_argmax  \n",
       "0       0.730327  \n",
       "1       0.875976  \n",
       "2       0.875976  \n",
       "3       0.686881  \n",
       "4       0.872722  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# reimplementation...\n",
    "text = \"Good night 😊\"\n",
    "#sentiment_df = pd.DataFrame(columns = ['text'])\n",
    "sentiments = ['negative', 'neutral', 'positive']\n",
    "\n",
    "df['roberta_negative'] = None\n",
    "df['roberta_neutral'] = None\n",
    "df['roberta_positive'] = None\n",
    "df['roberta_label'] = None\n",
    "df['roberta_score'] = None\n",
    "#for tweet in df['text']:\n",
    "for idx, row in df.iterrows():\n",
    "    # classify each tweet, row by row\n",
    "    encoded_input = tokenizer(row['text'], return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # update our data\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_label'] = sentiments[scores.argmax()]\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_argmax'] = scores.max()\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_negative'] = scores[0]\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_neutral'] = scores[1]\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_positive'] = scores[2]\n",
    "    \n",
    "    if idx % 500 == 0:\n",
    "        print(f'Through {idx} rows')\n",
    "    \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82e4d8ec-a403-4b15-bc71-46f211091559",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m tweet \u001b[38;5;241m=\u001b[39m preprocess(tweet)\n\u001b[1;32m      9\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m scores \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     12\u001b[0m scores \u001b[38;5;241m=\u001b[39m softmax(scores)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1216\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1216\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1228\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:852\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    843\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    845\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    846\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    847\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    850\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    851\u001b[0m )\n\u001b[0;32m--> 852\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    865\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    518\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    520\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:453\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    450\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    451\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 453\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/pytorch_utils.py:236\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:465\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 465\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:363\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 363\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = \"Good night 😊\"\n",
    "sentiment_df = pd.DataFrame(columns = ['text'])\n",
    "\n",
    "df['roberta_label'] = None\n",
    "df['roberta_score'] = None\n",
    "for tweet in df['text']:\n",
    "  tweet = preprocess(tweet)\n",
    "\n",
    "  encoded_input = tokenizer(text, return_tensors='pt')\n",
    "  output = model(**encoded_input)\n",
    "  scores = output[0][0].detach().numpy()\n",
    "  scores = softmax(scores)\n",
    "\n",
    "\n",
    "\n",
    "  ranking = np.argsort(scores)\n",
    "  ranking = ranking[::-1]\n",
    "  for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"tweet : {tweet} {i+1}) {l} {np.round(float(s), 4)}\")\n",
    "    row = {'text' : tweet, l: [np.round(float(s),4)]}\n",
    "    #Append row to the sentiment data frame\n",
    "    sentiment_df = sentiment_df.append(row, ignore_index = True)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed99cd4-3040-4ad2-9a55-11f9a2091eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we vectorize this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ff23b132-f57d-4477-83a7-921d308b2766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>...</th>\n",
       "      <th>geo.place_id</th>\n",
       "      <th>withheld.copyright</th>\n",
       "      <th>withheld.country_codes</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>roberta_label</th>\n",
       "      <th>roberta_score</th>\n",
       "      <th>roberta_negative</th>\n",
       "      <th>roberta_neutral</th>\n",
       "      <th>roberta_positive</th>\n",
       "      <th>roberta_argmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5067</th>\n",
       "      <td>1632968499302899712</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-07 04:56:43+00:00</td>\n",
       "      <td>rt  sagesurge marlon wayans roasting chris roc...</td>\n",
       "      <td>71163570</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632525319973289...</td>\n",
       "      <td>1632968499302899712</td>\n",
       "      <td>[1632968499302899713]</td>\n",
       "      <td>9130</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>1632968487302750208</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-07 04:56:41+00:00</td>\n",
       "      <td>rt  callme_tylor now this is funny  marlonwaya...</td>\n",
       "      <td>1340866792789581824</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632371347941740...</td>\n",
       "      <td>1632968487302750208</td>\n",
       "      <td>[1632968487302750210]</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>1632968431317254144</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-07 04:56:27+00:00</td>\n",
       "      <td>rt  sagesurge marlon wayans roasting chris roc...</td>\n",
       "      <td>3244783356</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632525319973289...</td>\n",
       "      <td>1632968431317254144</td>\n",
       "      <td>[1632968431317254144]</td>\n",
       "      <td>9130</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          conversation_id lang reply_settings                created_at   \n",
       "5067  1632968499302899712   en       everyone 2023-03-07 04:56:43+00:00  \\\n",
       "5068  1632968487302750208   en       everyone 2023-03-07 04:56:41+00:00   \n",
       "5069  1632968431317254144   en       everyone 2023-03-07 04:56:27+00:00   \n",
       "\n",
       "                                                   text            author_id   \n",
       "5067  rt  sagesurge marlon wayans roasting chris roc...             71163570  \\\n",
       "5068  rt  callme_tylor now this is funny  marlonwaya...  1340866792789581824   \n",
       "5069  rt  sagesurge marlon wayans roasting chris roc...           3244783356   \n",
       "\n",
       "                                      referenced_tweets                   id   \n",
       "5067  [{'type': 'retweeted', 'id': '1632525319973289...  1632968499302899712  \\\n",
       "5068  [{'type': 'retweeted', 'id': '1632371347941740...  1632968487302750208   \n",
       "5069  [{'type': 'retweeted', 'id': '1632525319973289...  1632968431317254144   \n",
       "\n",
       "     edit_history_tweet_ids  public_metrics.retweet_count  ...  geo.place_id   \n",
       "5067  [1632968499302899713]                          9130  ...          None  \\\n",
       "5068  [1632968487302750210]                            90  ...          None   \n",
       "5069  [1632968431317254144]                          9130  ...          None   \n",
       "\n",
       "      withheld.copyright  withheld.country_codes   \n",
       "5067                 NaN                    None  \\\n",
       "5068                 NaN                    None   \n",
       "5069                 NaN                    None   \n",
       "\n",
       "                                         polarity_score  roberta_label   \n",
       "5067  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...           None  \\\n",
       "5068  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...           None   \n",
       "5069  {'neg': 0.0, 'neu': 0.904, 'pos': 0.096, 'comp...           None   \n",
       "\n",
       "     roberta_score  roberta_negative roberta_neutral roberta_positive   \n",
       "5067          None              None            None             None  \\\n",
       "5068          None              None            None             None   \n",
       "5069          None              None            None             None   \n",
       "\n",
       "     roberta_argmax  \n",
       "5067            NaN  \n",
       "5068            NaN  \n",
       "5069            NaN  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ee5c2299-5614-4494-bf37-17552294a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data/roberta_on_chris.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "85584617-81b9-4177-a15d-9f9d99615ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30611, 37)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to run on all of our data:\n",
    "url = 'https://raw.githubusercontent.com/sareek/NLP_on_Social_Media_Data/main/data/normalized_annotated_all_2023-04-07_12.43.49.255973.tsv'\n",
    "\n",
    "df = pd.read_csv(url, sep='\\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "639bdc8b-032d-46e7-adab-925ca1a6ea92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Through 0 rows\n",
      "Through 500 rows\n",
      "Through 1000 rows\n",
      "Through 1500 rows\n",
      "Through 2000 rows\n",
      "Through 2500 rows\n",
      "Through 3000 rows\n",
      "Through 3500 rows\n",
      "Through 4000 rows\n",
      "Through 4500 rows\n",
      "Through 5000 rows\n",
      "Through 5500 rows\n",
      "Through 6000 rows\n",
      "Through 6500 rows\n",
      "Through 7000 rows\n",
      "Through 7500 rows\n",
      "Through 8000 rows\n",
      "Through 8500 rows\n",
      "Through 9000 rows\n",
      "Through 9500 rows\n",
      "Through 10000 rows\n",
      "Through 10500 rows\n",
      "Through 11000 rows\n",
      "Through 11500 rows\n",
      "Through 12000 rows\n",
      "Through 12500 rows\n",
      "Through 13000 rows\n",
      "Through 13500 rows\n",
      "Through 14000 rows\n",
      "Through 14500 rows\n",
      "Through 15000 rows\n",
      "Through 15500 rows\n",
      "Through 16000 rows\n",
      "Through 16500 rows\n",
      "Through 17000 rows\n",
      "Through 17500 rows\n",
      "Through 18000 rows\n",
      "Through 18500 rows\n",
      "Through 19000 rows\n",
      "Through 19500 rows\n",
      "Through 20000 rows\n",
      "Through 20500 rows\n",
      "Through 21000 rows\n",
      "Through 21500 rows\n",
      "Through 22000 rows\n",
      "Through 22500 rows\n",
      "Through 23000 rows\n",
      "Through 23500 rows\n",
      "Through 24000 rows\n",
      "Through 24500 rows\n",
      "Through 25000 rows\n",
      "Through 25500 rows\n",
      "Through 26000 rows\n",
      "Through 26500 rows\n",
      "Through 27000 rows\n",
      "Through 27500 rows\n",
      "Through 28000 rows\n",
      "Through 28500 rows\n",
      "Through 29000 rows\n",
      "Through 29500 rows\n",
      "Through 30000 rows\n",
      "Through 30500 rows\n",
      "CPU times: user 26min 26s, sys: 9min 35s, total: 36min 1s\n",
      "Wall time: 19min 57s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text</th>\n",
       "      <th>author_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>...</th>\n",
       "      <th>normalized_AFINN_scores</th>\n",
       "      <th>normalized_SentiWordNet_scores</th>\n",
       "      <th>our_label</th>\n",
       "      <th>annotator</th>\n",
       "      <th>roberta_negative</th>\n",
       "      <th>roberta_neutral</th>\n",
       "      <th>roberta_positive</th>\n",
       "      <th>roberta_label</th>\n",
       "      <th>roberta_score</th>\n",
       "      <th>roberta_argmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1633954063934009344</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:13:00+00:00</td>\n",
       "      <td>rt  infantry_bucky hes lucky a #chrisrocklive ...</td>\n",
       "      <td>RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...</td>\n",
       "      <td>1519164980582653952</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1633938373529292...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730327</td>\n",
       "      <td>0.228264</td>\n",
       "      <td>0.041409</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0.730327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1633954058212876288</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:12:59+00:00</td>\n",
       "      <td>rt  1_ofakindnocap chris rock we all been chea...</td>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>21575184</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875976</td>\n",
       "      <td>0.117147</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0.875976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1633951267423768576</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:01:54+00:00</td>\n",
       "      <td>rt  1_ofakindnocap chris rock we all been chea...</td>\n",
       "      <td>RT @1_ofakindnocap: Chris Rock: “we all been c...</td>\n",
       "      <td>360633018</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632283297588948...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875976</td>\n",
       "      <td>0.117147</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0.875976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1633950853626318848</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:15+00:00</td>\n",
       "      <td>rt  rolandsmartin working out and watching the...</td>\n",
       "      <td>RT @rolandsmartin: Working out and watching th...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632825595473149...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.686881</td>\n",
       "      <td>0.30526</td>\n",
       "      <td>neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.686881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1633950824664645632</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>2023-03-09 22:00:08+00:00</td>\n",
       "      <td>rt  rolandsmartin workout done ill have a few ...</td>\n",
       "      <td>RT @rolandsmartin: Workout done. I’ll have a f...</td>\n",
       "      <td>1547101103803830272</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1632833853021728...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010401</td>\n",
       "      <td>0.872722</td>\n",
       "      <td>0.116877</td>\n",
       "      <td>neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.872722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0      conversation_id lang reply_settings   \n",
       "0             0           0  1633954063934009344   en       everyone  \\\n",
       "1             1           1  1633954058212876288   en       everyone   \n",
       "2             2           2  1633951267423768576   en       everyone   \n",
       "3             3           3  1633950853626318848   en       everyone   \n",
       "4             4           4  1633950824664645632   en       everyone   \n",
       "\n",
       "                  created_at   \n",
       "0  2023-03-09 22:13:00+00:00  \\\n",
       "1  2023-03-09 22:12:59+00:00   \n",
       "2  2023-03-09 22:01:54+00:00   \n",
       "3  2023-03-09 22:00:15+00:00   \n",
       "4  2023-03-09 22:00:08+00:00   \n",
       "\n",
       "                                          clean_text   \n",
       "0  rt  infantry_bucky hes lucky a #chrisrocklive ...  \\\n",
       "1  rt  1_ofakindnocap chris rock we all been chea...   \n",
       "2  rt  1_ofakindnocap chris rock we all been chea...   \n",
       "3  rt  rolandsmartin working out and watching the...   \n",
       "4  rt  rolandsmartin workout done ill have a few ...   \n",
       "\n",
       "                                                text            author_id   \n",
       "0  RT @Infantry_bucky: He’s lucky a #ChrisRockLiv...  1519164980582653952  \\\n",
       "1  RT @1_ofakindnocap: Chris Rock: “we all been c...             21575184   \n",
       "2  RT @1_ofakindnocap: Chris Rock: “we all been c...            360633018   \n",
       "3  RT @rolandsmartin: Working out and watching th...  1547101103803830272   \n",
       "4  RT @rolandsmartin: Workout done. I’ll have a f...  1547101103803830272   \n",
       "\n",
       "                                   referenced_tweets  ...   \n",
       "0  [{'type': 'retweeted', 'id': '1633938373529292...  ...  \\\n",
       "1  [{'type': 'retweeted', 'id': '1632283297588948...  ...   \n",
       "2  [{'type': 'retweeted', 'id': '1632283297588948...  ...   \n",
       "3  [{'type': 'retweeted', 'id': '1632825595473149...  ...   \n",
       "4  [{'type': 'retweeted', 'id': '1632833853021728...  ...   \n",
       "\n",
       "   normalized_AFINN_scores normalized_SentiWordNet_scores  our_label   \n",
       "0                 0.448980                       0.444444        NaN  \\\n",
       "1                 0.367347                       0.333333        NaN   \n",
       "2                 0.367347                       0.333333        NaN   \n",
       "3                 0.489796                       0.412698        NaN   \n",
       "4                 0.489796                       0.412698        NaN   \n",
       "\n",
       "   annotator  roberta_negative  roberta_neutral  roberta_positive   \n",
       "0        NaN          0.730327         0.228264          0.041409  \\\n",
       "1        NaN          0.875976         0.117147          0.006877   \n",
       "2        NaN          0.875976         0.117147          0.006877   \n",
       "3        NaN          0.007859         0.686881           0.30526   \n",
       "4        NaN          0.010401         0.872722          0.116877   \n",
       "\n",
       "  roberta_label  roberta_score roberta_argmax  \n",
       "0      negative           None       0.730327  \n",
       "1      negative           None       0.875976  \n",
       "2      negative           None       0.875976  \n",
       "3       neutral           None       0.686881  \n",
       "4       neutral           None       0.872722  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# reimplementation...\n",
    "#text = \"Good night 😊\"\n",
    "#sentiment_df = pd.DataFrame(columns = ['text'])\n",
    "sentiments = ['negative', 'neutral', 'positive']\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "df['roberta_negative'] = None\n",
    "df['roberta_neutral'] = None\n",
    "df['roberta_positive'] = None\n",
    "df['roberta_label'] = None\n",
    "df['roberta_score'] = None\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    # classify each tweet, row by row\n",
    "    encoded_input = tokenizer(row['clean_text'], return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # update our data\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_label'] = sentiments[scores.argmax()]\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_argmax'] = scores.max()\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_negative'] = scores[0]\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_neutral'] = scores[1]\n",
    "    df.loc[df['conversation_id'] == row['conversation_id'], 'roberta_positive'] = scores[2]\n",
    "    \n",
    "    if idx % 500 == 0:\n",
    "        print(f'Through {idx} rows')\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b44d1-eaea-410a-964b-01498cfd39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('roberta_all.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a041a-e6cf-4e77-b84b-0f07336964e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('../../data/roberta_all.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5959dd7-2e1e-489b-9603-b2e748a4b6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
